{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d4efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° vc_analysis íŒ¨í‚¤ì§€ ë¡œë”© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# VC ë¶„ì„ ë¦¬íŒ©í„° V2 - ì„í”„ë¦°íŒ… ì „ì²˜ë¦¬ ë…¸íŠ¸ë¶\n",
    "# ì‘ì„±ì: í™ìŠ¹ì¬\n",
    "# ëª©ì : ì„í”„ë¦°íŒ… ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë„¤íŠ¸ì›Œí¬ ë¶„ì„\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# vc_analysis íŒ¨í‚¤ì§€ import\n",
    "import sys\n",
    "sys.path.append('/Users/suengj/Documents/Code/Python/Research/VC/refactor_v2')\n",
    "\n",
    "from vc_analysis import loader, merger\n",
    "from vc_analysis.data import filter as data_filter\n",
    "from vc_analysis.network import construction, centrality\n",
    "from vc_analysis.config import parameters\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° vc_analysis íŒ¨í‚¤ì§€ ë¡œë”© ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3fe48f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\n",
      "Round: 390011 rows\n",
      "Company: 61433 rows\n",
      "Firm: 15603 rows\n",
      "Fund: 39335 rows\n"
     ]
    }
   ],
   "source": [
    "# vc_analysis íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë¡œë”©\n",
    "data = loader.load_all_data()\n",
    "\n",
    "# Round ì •í•©ì„± í•„í„°ë§: firm ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ë°˜\n",
    "from vc_analysis.data import loader as data_loader\n",
    "\n",
    "# 1) ê¸°ë³¸(strict) ëª¨ë“œ: firmì— ì—†ëŠ” firmnameì€ roundì—ì„œ ì œê±°\n",
    "# í˜„ì¬ ë¶„ì„ì—ì„œëŠ” ë„¤íŠ¸ì›Œí¬ì˜ ë…¸ë“œë¶€í„° í•„í„°ë§í–ˆë‹¤ê³  ë³´ë©´ ë¨\n",
    "data['round'] = data_loader.filter_round_by_firm_registry(\n",
    "    round_df=data['round'],\n",
    "    firm_df=data['firm'],\n",
    "    mode='strict'\n",
    ")\n",
    "\n",
    "# 2) êµ­ê°€ ì„ íƒ ëª¨ë“œ ì˜ˆì‹œ: ë¯¸êµ­/ìºë‚˜ë‹¤ ë²•ì¸ë§Œ ìœ ì§€ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œ)\n",
    "# data['round'] = data_loader.filter_round_by_firm_registry(\n",
    "#     round_df=data['round'],\n",
    "#     firm_df=data['firm'],\n",
    "#     mode='nation_select',\n",
    "#     nation_codes=['US', 'CA']  # ì—¬ëŸ¬ ê°œ ê°€ëŠ¥\n",
    "# )\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ\")\n",
    "print(f\"Round: {len(data['round'])} rows\")\n",
    "print(f\"Company: {len(data['company'])} rows\") \n",
    "print(f\"Firm: {len(data['firm'])} rows\")\n",
    "print(f\"Fund: {len(data['fund'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebdb1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ë°ì´í„° ì •ë³´\n",
      "   - ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„: 1970 - 2022\n",
      "   - ì„ íƒëœ ë¶„ì„ ê¸°ê°„: 1980 - 2022\n",
      "   - ë„¤íŠ¸ì›Œí¬ ìœˆë„ìš°: 5ë…„\n",
      "   - ìƒì„±í•  ë„¤íŠ¸ì›Œí¬ ìˆ˜: 43ê°œ\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing networks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  8.35it/s]\n",
      "Computing centralities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:05<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ\n",
      "   - ìƒì„±ëœ ì—°ë„: 43ê°œ (1980-2022)\n",
      "   - í‰ê·  ë…¸ë“œ ìˆ˜: 2319\n",
      "   - í‰ê·  ì—£ì§€ ìˆ˜: 20930\n",
      "   - ì¤‘ì‹¬ì„± ë°ì´í„°: 99737 rows\n",
      "\n",
      "ğŸ“ˆ ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸°:\n",
      "   1980: 284 nodes, 1221 edges\n",
      "   1981: 355 nodes, 1955 edges\n",
      "   1982: 464 nodes, 3400 edges\n",
      "   1983: 613 nodes, 5381 edges\n",
      "   1984: 795 nodes, 9513 edges\n",
      "   1985: 970 nodes, 12882 edges\n",
      "   1986: 1086 nodes, 15503 edges\n",
      "   1987: 1149 nodes, 17847 edges\n",
      "   1988: 1147 nodes, 19362 edges\n",
      "   1989: 1129 nodes, 18613 edges\n",
      "   1990: 1121 nodes, 17364 edges\n",
      "   1991: 1071 nodes, 15821 edges\n",
      "   1992: 1005 nodes, 13328 edges\n",
      "   1993: 967 nodes, 11160 edges\n",
      "   1994: 915 nodes, 9436 edges\n",
      "   1995: 866 nodes, 8198 edges\n",
      "   1996: 998 nodes, 8229 edges\n",
      "   1997: 1179 nodes, 9307 edges\n",
      "   1998: 1361 nodes, 11079 edges\n",
      "   1999: 1637 nodes, 13554 edges\n",
      "   2000: 2108 nodes, 21246 edges\n",
      "   2001: 2683 nodes, 33977 edges\n",
      "   2002: 2886 nodes, 38354 edges\n",
      "   2003: 2991 nodes, 39836 edges\n",
      "   2004: 2987 nodes, 40765 edges\n",
      "   2005: 2980 nodes, 37935 edges\n",
      "   2006: 2805 nodes, 28054 edges\n",
      "   2007: 2745 nodes, 25600 edges\n",
      "   2008: 2842 nodes, 25502 edges\n",
      "   2009: 2930 nodes, 25569 edges\n",
      "   2010: 2955 nodes, 23990 edges\n",
      "   2011: 2997 nodes, 22855 edges\n",
      "   2012: 3067 nodes, 21913 edges\n",
      "   2013: 3109 nodes, 20320 edges\n",
      "   2014: 3187 nodes, 19266 edges\n",
      "   2015: 3455 nodes, 20252 edges\n",
      "   2016: 3700 nodes, 22750 edges\n",
      "   2017: 4016 nodes, 23728 edges\n",
      "   2018: 4319 nodes, 25854 edges\n",
      "   2019: 4749 nodes, 29856 edges\n",
      "   2020: 5151 nodes, 34072 edges\n",
      "   2021: 5545 nodes, 39307 edges\n",
      "   2022: 6418 nodes, 55833 edges\n"
     ]
    }
   ],
   "source": [
    "# vc_analysis íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•œ VC ë„¤íŠ¸ì›Œí¬ ìƒì„±\n",
    "\n",
    "# ë„¤íŠ¸ì›Œí¬ ì„¤ì •\n",
    "START_YEAR = 1980   # ë¶„ì„ ì‹œì‘ ì—°ë„\n",
    "# END_YEAR = 2000 # testing\n",
    "END_YEAR = 2022     # ë¶„ì„ ì¢…ë£Œ ì—°ë„\n",
    "TIME_WINDOW = 5     # ë„¤íŠ¸ì›Œí¬ êµ¬ì„± ê¸°ê°„ (ë…„)(ì˜ˆ: 1990ë…„ì´ë©´, 1986~1990ë…„ ë„¤íŠ¸ì›Œí¬)\n",
    "\n",
    "# 1. ë°ì´í„° í•„í„°ë§ (Angel, Other, Null ì œì™¸)\n",
    "filtered_round = data_filter.filter_by_vc_type(\n",
    "    data['round'], \n",
    "    exclude_types=['Angel', 'Other'], \n",
    "    type_column='firmtype2',\n",
    "    exclude_null=True  # Null ê°’ë„ ì œì™¸\n",
    ")\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„ ë²”ìœ„ í™•ì¸\n",
    "available_years = sorted(filtered_round['year'].dropna().unique())\n",
    "print(f\"ğŸ“Š ë°ì´í„° ì •ë³´\")\n",
    "print(f\"   - ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„: {available_years[0]} - {available_years[-1]}\")\n",
    "print(f\"   - ì„ íƒëœ ë¶„ì„ ê¸°ê°„: {START_YEAR} - {END_YEAR}\")\n",
    "print(f\"   - ë„¤íŠ¸ì›Œí¬ ìœˆë„ìš°: {TIME_WINDOW}ë…„\")\n",
    "print(f\"   - ìƒì„±í•  ë„¤íŠ¸ì›Œí¬ ìˆ˜: {END_YEAR - START_YEAR + 1}ê°œ\\n\")\n",
    "\n",
    "# 2. ë„¤íŠ¸ì›Œí¬ ìƒì„± (START_YEARë¶€í„° END_YEARê¹Œì§€)\n",
    "target_years = list(range(START_YEAR, END_YEAR + 1))\n",
    "networks = construction.construct_networks_for_years(\n",
    "    filtered_round, \n",
    "    years=target_years, \n",
    "    time_window=TIME_WINDOW\n",
    ")\n",
    "\n",
    "# 3. ì¤‘ì‹¬ì„± ê³„ì‚°\n",
    "centrality_df = centrality.compute_centralities_for_networks(networks)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nâœ… ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ìƒì„±ëœ ì—°ë„: {len(networks)}ê°œ ({START_YEAR}-{END_YEAR})\")\n",
    "print(f\"   - í‰ê·  ë…¸ë“œ ìˆ˜: {sum(len(G.nodes()) for G in networks.values()) / len(networks):.0f}\")\n",
    "print(f\"   - í‰ê·  ì—£ì§€ ìˆ˜: {sum(len(G.edges()) for G in networks.values()) / len(networks):.0f}\")\n",
    "print(f\"   - ì¤‘ì‹¬ì„± ë°ì´í„°: {len(centrality_df)} rows\")\n",
    "\n",
    "# ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸° ìš”ì•½\n",
    "print(f\"\\nğŸ“ˆ ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸°:\")\n",
    "for year in sorted(networks.keys()):\n",
    "    G = networks[year]\n",
    "    print(f\"   {year}: {len(G.nodes())} nodes, {len(G.edges())} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7559883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step 1: Initial Year ì‹ë³„ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)\n",
      "================================================================================\n",
      "\n",
      "âœ… Initial Year ì‹ë³„ ì™„ë£Œ (ì „ì²´ ìƒ˜í”Œ)\n",
      "   - ì´ Firm ìˆ˜: 11623\n",
      "   - ì—°ë„ ë²”ìœ„: 1970 ~ 2022\n",
      "\n",
      "================================================================================\n",
      "Step 2: ìƒ˜í”Œ í•„í„°ë§ (ì½”í˜¸íŠ¸ ì„ íƒ)\n",
      "================================================================================\n",
      "\n",
      "âœ… ìƒ˜í”Œ í•„í„°ë§ ì™„ë£Œ\n",
      "   - ì½”í˜¸íŠ¸ ê¸°ê°„: 1980 ~ 2022\n",
      "   - ì „ì²´ Firm: 11623\n",
      "   - ë¶„ì„ Firm: 11296 (97.2%)\n",
      "   - ì œì™¸ Firm: 327\n",
      "   - ë¶„ì„ ì—°ë„ ë²”ìœ„: 1980 ~ 2022\n",
      "\n",
      "ìƒ˜í”Œ:\n",
      "                     firmname  initial_year\n",
      "0           01 Advisors 01 LP          2019\n",
      "1      1 Flourish Capital LLC          2021\n",
      "2        10 Point Capital LLC          2018\n",
      "3            100 X Better Inc          2000\n",
      "4  10X Capital Management LLC          2020\n",
      "\n",
      "================================================================================\n",
      "Step 3: í•„ìš”í•œ ì—°ë„ ë„¤íŠ¸ì›Œí¬ ìƒì„±\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ë„¤íŠ¸ì›Œí¬ ìƒì„± ì •ë³´\n",
      "   - Imprinting Period: 3ë…„\n",
      "   - ë¶„ì„ Firm ìˆ˜: 11296\n",
      "   - í•„ìš”í•œ ë„¤íŠ¸ì›Œí¬ ì—°ë„: 45ê°œ\n",
      "   - ì—°ë„ ë²”ìœ„: 1980 ~ 2024\n",
      "   - Time Window: 5ë…„ (ê° ì—°ë„ë³„)\n",
      "\n",
      "ğŸ”„ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing networks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:04<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ ì¤‘ì‹¬ì„± ê³„ì‚° ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing centralities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [00:33<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ\n",
      "   - ìƒì„±ëœ ë„¤íŠ¸ì›Œí¬: 45ê°œ\n",
      "   - í‰ê·  ë…¸ë“œ ìˆ˜: 2522\n",
      "   - í‰ê·  ì—£ì§€ ìˆ˜: 22907\n",
      "   - ì¤‘ì‹¬ì„± ë°ì´í„°: 113489 rows\n",
      "\n",
      "ğŸ“ˆ ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸° (ìƒ˜í”Œ):\n",
      "   1980: 284 nodes, 1221 edges\n",
      "   1981: 355 nodes, 1955 edges\n",
      "   1982: 464 nodes, 3400 edges\n",
      "   1983: 613 nodes, 5381 edges\n",
      "   1984: 795 nodes, 9513 edges\n",
      "   2020: 5151 nodes, 34072 edges\n",
      "   2021: 5545 nodes, 39307 edges\n",
      "   2022: 6418 nodes, 55833 edges\n",
      "   2023: 7053 nodes, 68468 edges\n",
      "   2024: 6699 nodes, 62382 edges\n",
      "   ... (35ê°œ ì—°ë„ ìƒëµ)\n",
      "\n",
      "================================================================================\n",
      "Step 4: Initial Partners ì¶”ì¶œ (ì§„ì§œ Imprinting Period)\n",
      "\n",
      "âœ… Initial Partners ì¶”ì¶œ ì™„ë£Œ\n",
      "   - ì´ Partnership ìˆ˜: 114679\n",
      "   - Focal Firm ìˆ˜: 8276\n",
      "   - Unique Partner ìˆ˜: 7241\n",
      "   - ì—°ë„ ë²”ìœ„: 1981 ~ 2024\n",
      "\n",
      "ìƒ˜í”Œ (ì§„ì§œ imprinting period):\n",
      "            firmname                  initial_partner  tied_year  initial_year\n",
      "0  01 Advisors 01 LP           Nexus Venture Partners       2020          2019\n",
      "1  01 Advisors 01 LP       Greenspring Associates LLC       2020          2019\n",
      "2  01 Advisors 01 LP           Scale Venture Partners       2020          2019\n",
      "3  01 Advisors 01 LP  Zeev Ventures Management II LLC       2020          2019\n",
      "4  01 Advisors 01 LP             Emergent Ventures LP       2020          2019\n",
      "5  01 Advisors 01 LP                        SG VC LLC       2020          2019\n",
      "6  01 Advisors 01 LP  Truebridge Capital Partners LLC       2021          2019\n",
      "7  01 Advisors 01 LP       Greenspring Associates LLC       2021          2019\n",
      "8  01 Advisors 01 LP              Battery Ventures LP       2021          2019\n",
      "9  01 Advisors 01 LP                Founders Fund LLC       2021          2019\n",
      "\n",
      "================================================================================\n",
      "Step 5: Partner Centrality ë³‘í•© (í•´ë‹¹ ì‹œì )\n",
      "================================================================================\n",
      "\n",
      "âœ… Partner Centrality ë³‘í•© ì™„ë£Œ\n",
      "   - ì´ í–‰ ìˆ˜: 114679\n",
      "   - ì¤‘ì‹¬ì„± ë³€ìˆ˜: ['partner_dgr_cent', 'partner_btw_cent', 'partner_pwr_max', 'partner_pwr_p0', 'partner_pwr_p75', 'partner_pwr_p99', 'partner_constraint', 'partner_ego_dens']\n",
      "\n",
      "ìƒ˜í”Œ:\n",
      "            firmname                  initial_partner  tied_year  \\\n",
      "0  01 Advisors 01 LP           Nexus Venture Partners       2020   \n",
      "1  01 Advisors 01 LP       Greenspring Associates LLC       2020   \n",
      "2  01 Advisors 01 LP           Scale Venture Partners       2020   \n",
      "3  01 Advisors 01 LP  Zeev Ventures Management II LLC       2020   \n",
      "4  01 Advisors 01 LP             Emergent Ventures LP       2020   \n",
      "\n",
      "   initial_year  partner_dgr_cent  partner_btw_cent  \n",
      "0          2019                66          0.000655  \n",
      "1          2019               109          0.001357  \n",
      "2          2019               144          0.001907  \n",
      "3          2019                32          0.000165  \n",
      "4          2019                13          0.000013  \n",
      "\n",
      "================================================================================\n",
      "Step 6: Initial Partner Status ê³„ì‚° (Mean, Max, Min)\n",
      "================================================================================\n",
      "\n",
      "âœ… Initial Partner Status ê³„ì‚° ì™„ë£Œ\n",
      "   - Focal Firm ìˆ˜: 8276\n",
      "   - ë³€ìˆ˜ ìˆ˜: 28\n",
      "\n",
      "ìƒì„±ëœ Status ë³€ìˆ˜:\n",
      "   - initial_year\n",
      "   - initial_dgr_cent_mean\n",
      "   - initial_dgr_cent_max\n",
      "   - initial_dgr_cent_min\n",
      "   - initial_btw_cent_mean\n",
      "   - initial_btw_cent_max\n",
      "   - initial_btw_cent_min\n",
      "   - initial_pwr_max_mean\n",
      "   - initial_pwr_max_max\n",
      "   - initial_pwr_max_min\n",
      "   - initial_pwr_p0_mean\n",
      "   - initial_pwr_p0_max\n",
      "   - initial_pwr_p0_min\n",
      "   - initial_pwr_p75_mean\n",
      "   - initial_pwr_p75_max\n",
      "   - initial_pwr_p75_min\n",
      "   - initial_pwr_p99_mean\n",
      "   - initial_pwr_p99_max\n",
      "   - initial_pwr_p99_min\n",
      "   - initial_constraint_mean\n",
      "   - initial_constraint_max\n",
      "   - initial_constraint_min\n",
      "   - initial_ego_dens_mean\n",
      "   - initial_ego_dens_max\n",
      "   - initial_ego_dens_min\n",
      "\n",
      "ê¸°ìˆ  í†µê³„ (Degree Centrality ê¸°ì¤€):\n",
      "       n_initial_partners  n_partner_years  initial_dgr_cent_mean  \\\n",
      "count         8276.000000      8276.000000            8276.000000   \n",
      "mean             9.037820        13.856815              72.836768   \n",
      "std             11.904236        17.316319              59.281819   \n",
      "min              1.000000         1.000000               1.000000   \n",
      "25%              2.000000         4.000000              25.411458   \n",
      "50%              5.000000         8.000000              65.386752   \n",
      "75%             11.000000        17.000000             105.269231   \n",
      "max            186.000000       302.000000             741.500000   \n",
      "\n",
      "       initial_dgr_cent_max  initial_dgr_cent_min  \n",
      "count           8276.000000           8276.000000  \n",
      "mean             194.016735             19.179676  \n",
      "std              179.567619             39.452978  \n",
      "min                1.000000              1.000000  \n",
      "25%               43.000000              4.000000  \n",
      "50%              151.000000              7.000000  \n",
      "75%              288.500000             17.500000  \n",
      "max              765.000000            741.500000  \n",
      "\n",
      "ìƒ˜í”Œ:\n",
      "                     firmname  initial_year  n_initial_partners  \\\n",
      "0           01 Advisors 01 LP          2019                  22   \n",
      "1      1 Flourish Capital LLC          2021                   4   \n",
      "2  10X Capital Management LLC          2020                  37   \n",
      "3    10X Venture Partners LLC          2012                   2   \n",
      "4                   11 Tribes          2022                   7   \n",
      "\n",
      "   initial_dgr_cent_mean  initial_dgr_cent_max  initial_dgr_cent_min  \n",
      "0             122.159091                 486.0                   8.0  \n",
      "1              97.000000                 173.0                  53.0  \n",
      "2              77.135135                 476.0                   2.0  \n",
      "3              13.500000                  25.0                   2.0  \n",
      "4             184.642857                 741.5                   2.0  \n",
      "\n",
      "================================================================================\n",
      "âœ… Initial Network Partner íŠ¹ì„± ê³„ì‚° ì™„ë£Œ! (Option A)\n",
      "================================================================================\n",
      "\n",
      "ìµœì¢… ë°ì´í„°ì…‹: initial_ties_df\n",
      "   - Shape: (8276, 28)\n",
      "   - Focal Firm ìˆ˜: 8276\n",
      "   - Initial Year ë²”ìœ„: 1980 ~ 2022\n",
      "   - ìƒ˜í”Œ ê¸°ì¤€: 1980~2022 ì½”í˜¸íŠ¸\n",
      "\n",
      "ë°©ë²•ë¡ :\n",
      "   - Option A (Full History): ì „ì²´ ë°ì´í„°ë¡œ ì§„ì§œ initial year ì‹ë³„\n",
      "   - ì§„ì§œ imprinting period (t1~t3)ì˜ íŒŒíŠ¸ë„ˆ íŠ¹ì„± ê³„ì‚°\n",
      "   - í•´ë‹¹ ì‹œì ì˜ ì •í™•í•œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ì‚¬ìš©\n",
      "   - Partner-weighted: ê° íŒŒíŠ¸ë„ˆì˜ ì‹œê°„ í‰ê· ì„ ë¨¼ì € ê³„ì‚° í›„ ì§‘ê³„\n",
      "\n",
      "í™œìš©:\n",
      "   - Option 1 (Mean): ê¸°ë³¸ í†µì œ ë³€ìˆ˜ (íŒŒíŠ¸ë„ˆ í‰ê· ì˜ í‰ê· )\n",
      "   - Option 2 (Max) & Option 3 (Min): ì§€ìœ„ ì´ì ê³¼ ë¶ˆì´ìµ íš¨ê³¼ ê²€ì¦\n",
      "\n",
      "ìœ ì—°ì„±:\n",
      "   - ì„±ê³¼ ë°ì´í„°ì™€ mergeí•˜ì—¬ ë¶„ì„\n",
      "   - ë˜ëŠ” initial_yearë¡œ ë‹¤ë¥¸ ì½”í˜¸íŠ¸ ë¶„ì„ ê°€ëŠ¥\n",
      "   - ì˜ˆ: initial_ties_df[initial_ties_df['initial_year'].between(1990, 1995)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Initial Network Partner íŠ¹ì„± ê³„ì‚° (Imprinting Analysis) - Option A\n",
    "================================================================================\n",
    "\n",
    "ì—°êµ¬ ëª©ì :\n",
    "---------\n",
    "Focal Firmì˜ Initial Network Partner íŠ¹ì„±ì„ Podolnyì˜ ì§€ìœ„ ì´ë¡ ì— ê¸°ë°˜í•˜ì—¬ ê³„ì‚°.\n",
    "ê° Firmì´ ìµœì´ˆë¡œ VC ë„¤íŠ¸ì›Œí¬ë¥¼ í˜•ì„±í•œ ì‹œì (t1)ë¶€í„° 3ë…„(t1~t3) ë™ì•ˆ ë§ºì€ \n",
    "íŒŒíŠ¸ë„ˆì˜ ì§€ìœ„(ì¤‘ì‹¬ì„±)ë¥¼ ì„¸ ê°€ì§€ ë°©ì‹ìœ¼ë¡œ ì¸¡ì •.\n",
    "\n",
    "ë°©ë²•ë¡ ì  ì ‘ê·¼ (Option A: Full History):\n",
    "-------------------------------------\n",
    "1. ì „ì²´ ë°ì´í„°ë¡œ ê° Firmì˜ ì§„ì§œ Initial Year ì‹ë³„\n",
    "   - ì˜ˆ: Firm Aê°€ 1972ë…„ì— ì²˜ìŒ ë“±ì¥ â†’ initial_year = 1972\n",
    "   - 1990~1995 ê¸°ê°„ì€ ì„±ê³¼ ì¸¡ì • ê¸°ê°„ì¼ ë¿, initial year ì‹ë³„ì—ëŠ” ì „ì²´ ì´ë ¥ ì‚¬ìš©\n",
    "   \n",
    "2. ì§„ì§œ Imprinting Periodì˜ Initial Partners ì¶”ì¶œ\n",
    "   - Firm A: 1972~1974ë…„ íŒŒíŠ¸ë„ˆë“¤ (ì§„ì§œ imprinting period)\n",
    "   - ì´ ê¸°ê°„ì˜ íŒŒíŠ¸ë„ˆ ì¤‘ì‹¬ì„±ë„ í•´ë‹¹ ì‹œì  ë„¤íŠ¸ì›Œí¬ë¡œ ê³„ì‚°\n",
    "   \n",
    "3. ìƒ˜í”Œ ì„ íƒ (Left-Censoring í†µì œ):\n",
    "   - 1980ë…„ ì´í›„ initial tiesë¥¼ í˜•ì„±í•œ Firmë§Œ ë¶„ì„\n",
    "   - ì´ìœ : 1970ë…„ëŒ€ ì´ˆê¸° ë°ì´í„° í’ˆì§ˆ ë° left-censoring ë¬¸ì œ\n",
    "\n",
    "ê³„ì‚° ë°©ë²• (Partner-Weighted):\n",
    "-----------------------------\n",
    "1. Initial Year ì‹ë³„: ì „ì²´ ë°ì´í„°ì—ì„œ ê° Firmì˜ ìµœì´ˆ ë„¤íŠ¸ì›Œí¬ í˜•ì„± ì‹œì (t1) íŒŒì•…\n",
    "2. ìƒ˜í”Œ í•„í„°ë§: START_YEAR ~ END_YEAR ì½”í˜¸íŠ¸ ì„ íƒ\n",
    "3. í•„ìš”í•œ ë„¤íŠ¸ì›Œí¬ ìƒì„±: ìƒ˜í”Œ Firmë“¤ì˜ imprinting periodì— í•„ìš”í•œ ì—°ë„ë§Œ\n",
    "4. Initial Partner ì¶”ì¶œ: t1~t3 ê¸°ê°„ ë™ì•ˆ ë§ºì€ ëª¨ë“  unique íŒŒíŠ¸ë„ˆ ë¦¬ìŠ¤íŠ¸\n",
    "5. Partner Centrality ê³„ì‚°: ê° íŒŒíŠ¸ë„ˆì˜ t1, t2, t3 ì‹œì ë³„ ì¤‘ì‹¬ì„± ê°’\n",
    "   - ê° ì‹œì ì˜ ì¤‘ì‹¬ì„±ì€ 5-year moving window (t-5 ~ t-1) ë„¤íŠ¸ì›Œí¬ ê¸°ë°˜\n",
    "6. ì„¸ ê°€ì§€ Status ë³€ìˆ˜ ê³„ì‚° (Partner-Weighted):\n",
    "   \n",
    "   Step 1: ê° íŒŒíŠ¸ë„ˆì˜ ì‹œê°„ í‰ê·  ê³„ì‚°\n",
    "   - Partner B: (cent_t1 + cent_t2) / 2 = avg_B\n",
    "   - Partner C: (cent_t1 + cent_t3) / 2 = avg_C\n",
    "   - Partner D: cent_t2 = avg_D\n",
    "   \n",
    "   Step 2: íŒŒíŠ¸ë„ˆ í‰ê· ë“¤ë¡œë¶€í„° ì§‘ê³„\n",
    "   \n",
    "   Option 1 (Mean Status - Control/Baseline):\n",
    "   - ê° íŒŒíŠ¸ë„ˆ í‰ê· ì˜ í‰ê· \n",
    "   - ìˆ˜ì‹: (avg_B + avg_C + avg_D) / |P|\n",
    "   - ì˜ë¯¸: ì´ˆê¸° íŒŒíŠ¸ë„ˆë“¤ì˜ í‰ê·  ì§€ìœ„ (íŒŒíŠ¸ë„ˆ ë™ë“± ê°€ì¤‘)\n",
    "   \n",
    "   Option 2 (Max Status - Benefit Variable):\n",
    "   - ê° íŒŒíŠ¸ë„ˆ í‰ê·  ì¤‘ ìµœëŒ€ê°’\n",
    "   - ìˆ˜ì‹: max(avg_B, avg_C, avg_D)\n",
    "   - ì˜ë¯¸: ìµœê³  ì§€ìœ„ íŒŒíŠ¸ë„ˆì˜ ì˜í–¥ë ¥ (í˜œíƒ)\n",
    "   \n",
    "   Option 3 (Min Status - Penalty Variable):\n",
    "   - ê° íŒŒíŠ¸ë„ˆ í‰ê·  ì¤‘ ìµœì†Œê°’\n",
    "   - ìˆ˜ì‹: min(avg_B, avg_C, avg_D)\n",
    "   - ì˜ë¯¸: ìµœì € ì§€ìœ„ íŒŒíŠ¸ë„ˆì˜ ì˜¤ì—¼ íš¨ê³¼ (í˜ë„í‹°)\n",
    "\n",
    "í™œìš©:\n",
    "-----\n",
    "- Option 1: ê¸°ë³¸ í†µì œ ë³€ìˆ˜\n",
    "- Option 2 & 3: í•¨ê»˜ íšŒê·€ ëª¨í˜•ì— íˆ¬ì…í•˜ì—¬ ì§€ìœ„ ì´ì ê³¼ ë¶ˆì´ìµ íš¨ê³¼ ë™ì‹œ ê²€ì¦\n",
    "\"\"\"\n",
    "\n",
    "from vc_analysis.network import imprinting\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: ì „ì²´ ë°ì´í„°ë¡œ ê° Firmì˜ ì§„ì§œ Initial Year ì‹ë³„\n",
    "# ============================================================================\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 1: Initial Year ì‹ë³„ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¡œ initial year ì‹ë³„ (Angel/Other/Null ì œì™¸ëœ filtered_round ì‚¬ìš©)\n",
    "full_initial_year_df = imprinting.identify_initial_year(\n",
    "    filtered_round,  # ì „ì²´ ì—°ë„ í¬í•¨ (1970~2022)\n",
    "    firm_col='firmname',\n",
    "    year_col='year'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Initial Year ì‹ë³„ ì™„ë£Œ (ì „ì²´ ìƒ˜í”Œ)\")\n",
    "print(f\"   - ì´ Firm ìˆ˜: {len(full_initial_year_df)}\")\n",
    "print(f\"   - ì—°ë„ ë²”ìœ„: {full_initial_year_df['initial_year'].min():.0f} ~ {full_initial_year_df['initial_year'].max():.0f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: ìƒ˜í”Œ í•„í„°ë§ (ì½”í˜¸íŠ¸ ì„ íƒ)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 2: ìƒ˜í”Œ í•„í„°ë§ (ì½”í˜¸íŠ¸ ì„ íƒ)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ì½”í˜¸íŠ¸ ê¸°ê°„ ì„¤ì • (START_YEAR ~ END_YEARì— initial ties í˜•ì„±í•œ firmë§Œ)\n",
    "initial_year_df = full_initial_year_df[\n",
    "    full_initial_year_df['initial_year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nâœ… ìƒ˜í”Œ í•„í„°ë§ ì™„ë£Œ\")\n",
    "print(f\"   - ì½”í˜¸íŠ¸ ê¸°ê°„: {START_YEAR} ~ {END_YEAR}\")\n",
    "print(f\"   - ì „ì²´ Firm: {len(full_initial_year_df)}\")\n",
    "print(f\"   - ë¶„ì„ Firm: {len(initial_year_df)} ({len(initial_year_df)/len(full_initial_year_df)*100:.1f}%)\")\n",
    "print(f\"   - ì œì™¸ Firm: {len(full_initial_year_df) - len(initial_year_df)}\")\n",
    "print(f\"   - ë¶„ì„ ì—°ë„ ë²”ìœ„: {initial_year_df['initial_year'].min():.0f} ~ {initial_year_df['initial_year'].max():.0f}\")\n",
    "print(f\"\\nìƒ˜í”Œ:\")\n",
    "print(initial_year_df.head())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: í•„ìš”í•œ ì—°ë„ì˜ ë„¤íŠ¸ì›Œí¬ ìƒì„± (Imprinting Periodìš©)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 3: í•„ìš”í•œ ì—°ë„ ë„¤íŠ¸ì›Œí¬ ìƒì„±\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "IMPRINTING_PERIOD = 3  # t1, t2, t3\n",
    "\n",
    "# í•„ìš”í•œ ì—°ë„ íŒŒì•… (ê° firmì˜ imprinting period)\n",
    "needed_years = set()\n",
    "for _, row in initial_year_df.iterrows():\n",
    "    t1 = int(row['initial_year'])\n",
    "    for offset in range(IMPRINTING_PERIOD):\n",
    "        needed_years.add(t1 + offset)\n",
    "\n",
    "needed_years = sorted(needed_years)\n",
    "\n",
    "print(f\"\\nğŸ“Š ë„¤íŠ¸ì›Œí¬ ìƒì„± ì •ë³´\")\n",
    "print(f\"   - Imprinting Period: {IMPRINTING_PERIOD}ë…„\")\n",
    "print(f\"   - ë¶„ì„ Firm ìˆ˜: {len(initial_year_df)}\")\n",
    "print(f\"   - í•„ìš”í•œ ë„¤íŠ¸ì›Œí¬ ì—°ë„: {len(needed_years)}ê°œ\")\n",
    "print(f\"   - ì—°ë„ ë²”ìœ„: {needed_years[0]} ~ {needed_years[-1]}\")\n",
    "print(f\"   - Time Window: {TIME_WINDOW}ë…„ (ê° ì—°ë„ë³„)\")\n",
    "\n",
    "# í•„ìš”í•œ ì—°ë„ì˜ ë„¤íŠ¸ì›Œí¬ ìƒì„±\n",
    "print(f\"\\nğŸ”„ ë„¤íŠ¸ì›Œí¬ ìƒì„± ì¤‘...\")\n",
    "imprinting_networks = construction.construct_networks_for_years(\n",
    "    filtered_round,  # ì „ì²´ ë°ì´í„° (Angel/Other/Null ì œì™¸)\n",
    "    years=needed_years,\n",
    "    time_window=TIME_WINDOW\n",
    ")\n",
    "\n",
    "# ì¤‘ì‹¬ì„± ê³„ì‚°\n",
    "print(f\"ğŸ”„ ì¤‘ì‹¬ì„± ê³„ì‚° ì¤‘...\")\n",
    "imprinting_centrality_df = centrality.compute_centralities_for_networks(imprinting_networks)\n",
    "\n",
    "print(f\"\\nâœ… ë„¤íŠ¸ì›Œí¬ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ìƒì„±ëœ ë„¤íŠ¸ì›Œí¬: {len(imprinting_networks)}ê°œ\")\n",
    "print(f\"   - í‰ê·  ë…¸ë“œ ìˆ˜: {sum(len(G.nodes()) for G in imprinting_networks.values()) / len(imprinting_networks):.0f}\")\n",
    "print(f\"   - í‰ê·  ì—£ì§€ ìˆ˜: {sum(len(G.edges()) for G in imprinting_networks.values()) / len(imprinting_networks):.0f}\")\n",
    "print(f\"   - ì¤‘ì‹¬ì„± ë°ì´í„°: {len(imprinting_centrality_df)} rows\")\n",
    "\n",
    "# ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ, ë§ˆì§€ë§‰ 5ê°œ)\n",
    "print(f\"\\nğŸ“ˆ ì—°ë„ë³„ ë„¤íŠ¸ì›Œí¬ í¬ê¸° (ìƒ˜í”Œ):\")\n",
    "sample_years = needed_years[:5] + needed_years[-5:]\n",
    "for year in sorted(set(sample_years)):\n",
    "    if year in imprinting_networks:\n",
    "        G = imprinting_networks[year]\n",
    "        print(f\"   {year}: {len(G.nodes())} nodes, {len(G.edges())} edges\")\n",
    "if len(needed_years) > 10:\n",
    "    print(f\"   ... ({len(needed_years) - 10}ê°œ ì—°ë„ ìƒëµ)\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4: Initial Partners ì¶”ì¶œ (ì§„ì§œ Imprinting Period)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 4: Initial Partners ì¶”ì¶œ (ì§„ì§œ Imprinting Period)\")\n",
    "\n",
    "initial_partners_df = imprinting.extract_initial_partners(\n",
    "    filtered_round,  # ì „ì²´ ë°ì´í„°\n",
    "    imprinting_networks,  # í•„ìš”í•œ ì—°ë„ì˜ ë„¤íŠ¸ì›Œí¬\n",
    "    initial_year_df,  # 1980ë…„ ì´í›„ firmë§Œ\n",
    "    imprinting_period=IMPRINTING_PERIOD,\n",
    "    firm_col='firmname'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Initial Partners ì¶”ì¶œ ì™„ë£Œ\")\n",
    "print(f\"   - ì´ Partnership ìˆ˜: {len(initial_partners_df)}\")\n",
    "print(f\"   - Focal Firm ìˆ˜: {initial_partners_df['firmname'].nunique()}\")\n",
    "print(f\"   - Unique Partner ìˆ˜: {initial_partners_df['initial_partner'].nunique()}\")\n",
    "print(f\"   - ì—°ë„ ë²”ìœ„: {initial_partners_df['tied_year'].min():.0f} ~ {initial_partners_df['tied_year'].max():.0f}\")\n",
    "print(f\"\\nìƒ˜í”Œ (ì§„ì§œ imprinting period):\")\n",
    "print(initial_partners_df.head(10))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 5: Partner Centrality ë³‘í•© (í•´ë‹¹ ì‹œì ì˜ ì§„ì§œ ì¤‘ì‹¬ì„±)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 5: Partner Centrality ë³‘í•© (í•´ë‹¹ ì‹œì )\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "initial_ties_with_cent = imprinting.calculate_partner_centrality_by_year(\n",
    "    initial_partners_df,\n",
    "    imprinting_centrality_df,  # imprinting period ì¤‘ì‹¬ì„± ì‚¬ìš©\n",
    "    firm_col='firmname'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Partner Centrality ë³‘í•© ì™„ë£Œ\")\n",
    "print(f\"   - ì´ í–‰ ìˆ˜: {len(initial_ties_with_cent)}\")\n",
    "print(f\"   - ì¤‘ì‹¬ì„± ë³€ìˆ˜: {[col for col in initial_ties_with_cent.columns if col.startswith('partner_')]}\")\n",
    "print(f\"\\nìƒ˜í”Œ:\")\n",
    "print(initial_ties_with_cent[['firmname', 'initial_partner', 'tied_year', 'initial_year', \n",
    "                               'partner_dgr_cent', 'partner_btw_cent']].head())\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Step 6: Initial Partner Status ê³„ì‚° (Option 1, 2, 3)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 6: Initial Partner Status ê³„ì‚° (Mean, Max, Min)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ëª¨ë“  ì¤‘ì‹¬ì„± ì§€í‘œì— ëŒ€í•´ ê³„ì‚°\n",
    "initial_ties_df = imprinting.compute_all_initial_partner_status(\n",
    "    initial_ties_with_cent,\n",
    "    centrality_measures=None,  # None = ëª¨ë“  ì¤‘ì‹¬ì„± ì§€í‘œ ì‚¬ìš©\n",
    "    firm_col='firmname'\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Initial Partner Status ê³„ì‚° ì™„ë£Œ\")\n",
    "print(f\"   - Focal Firm ìˆ˜: {len(initial_ties_df)}\")\n",
    "print(f\"   - ë³€ìˆ˜ ìˆ˜: {len(initial_ties_df.columns)}\")\n",
    "print(f\"\\nìƒì„±ëœ Status ë³€ìˆ˜:\")\n",
    "status_vars = [col for col in initial_ties_df.columns if col.startswith('initial_')]\n",
    "for var in status_vars:\n",
    "    print(f\"   - {var}\")\n",
    "\n",
    "print(f\"\\nê¸°ìˆ  í†µê³„ (Degree Centrality ê¸°ì¤€):\")\n",
    "print(initial_ties_df[['n_initial_partners', 'n_partner_years',\n",
    "                        'initial_dgr_cent_mean', 'initial_dgr_cent_max', \n",
    "                        'initial_dgr_cent_min']].describe())\n",
    "\n",
    "print(f\"\\nìƒ˜í”Œ:\")\n",
    "print(initial_ties_df[['firmname', 'initial_year', 'n_initial_partners',\n",
    "                        'initial_dgr_cent_mean', 'initial_dgr_cent_max', \n",
    "                        'initial_dgr_cent_min']].head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… Initial Network Partner íŠ¹ì„± ê³„ì‚° ì™„ë£Œ! (Option A)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nìµœì¢… ë°ì´í„°ì…‹: initial_ties_df\")\n",
    "print(f\"   - Shape: {initial_ties_df.shape}\")\n",
    "print(f\"   - Focal Firm ìˆ˜: {len(initial_ties_df)}\")\n",
    "if 'initial_year' in initial_ties_df.columns and len(initial_ties_df) > 0:\n",
    "    min_year = initial_ties_df['initial_year'].min()\n",
    "    max_year = initial_ties_df['initial_year'].max()\n",
    "    print(f\"   - Initial Year ë²”ìœ„: {min_year} ~ {max_year}\")\n",
    "else:\n",
    "    print(f\"   - Initial Year ì •ë³´ ì—†ìŒ\")\n",
    "print(f\"   - ìƒ˜í”Œ ê¸°ì¤€: {START_YEAR}~{END_YEAR} ì½”í˜¸íŠ¸\")\n",
    "print(f\"\\në°©ë²•ë¡ :\")\n",
    "print(f\"   - Option A (Full History): ì „ì²´ ë°ì´í„°ë¡œ ì§„ì§œ initial year ì‹ë³„\")\n",
    "print(f\"   - ì§„ì§œ imprinting period (t1~t3)ì˜ íŒŒíŠ¸ë„ˆ íŠ¹ì„± ê³„ì‚°\")\n",
    "print(f\"   - í•´ë‹¹ ì‹œì ì˜ ì •í™•í•œ ë„¤íŠ¸ì›Œí¬ ì¤‘ì‹¬ì„± ì‚¬ìš©\")\n",
    "print(f\"   - Partner-weighted: ê° íŒŒíŠ¸ë„ˆì˜ ì‹œê°„ í‰ê· ì„ ë¨¼ì € ê³„ì‚° í›„ ì§‘ê³„\")\n",
    "print(f\"\\ní™œìš©:\")\n",
    "print(f\"   - Option 1 (Mean): ê¸°ë³¸ í†µì œ ë³€ìˆ˜ (íŒŒíŠ¸ë„ˆ í‰ê· ì˜ í‰ê· )\")\n",
    "print(f\"   - Option 2 (Max) & Option 3 (Min): ì§€ìœ„ ì´ì ê³¼ ë¶ˆì´ìµ íš¨ê³¼ ê²€ì¦\")\n",
    "print(f\"\\nìœ ì—°ì„±:\")\n",
    "print(f\"   - ì„±ê³¼ ë°ì´í„°ì™€ mergeí•˜ì—¬ ë¶„ì„\")\n",
    "print(f\"   - ë˜ëŠ” initial_yearë¡œ ë‹¤ë¥¸ ì½”í˜¸íŠ¸ ë¶„ì„ ê°€ëŠ¥\")\n",
    "print(f\"   - ì˜ˆ: initial_ties_df[initial_ties_df['initial_year'].between(1990, 1995)]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2f5760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Firm-Level ê¸°ë³¸ ë³€ìˆ˜ ìƒì„±\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ ë³€ìˆ˜ ìƒì„± ì¤‘...\n",
      "   - ë¶„ì„ ê¸°ê°„: 1980 ~ 2022\n",
      "   - ìƒì„± ë³€ìˆ˜: 9ê°œ\n",
      "ğŸ” New Venture Funding Demand ê³„ì‚° ì „ ì»¬ëŸ¼ í™•ì¸:\n",
      "  - round_df ì»¬ëŸ¼: RoundNumber ì¡´ì¬ ì—¬ë¶€ = True\n",
      "    RoundNumber non-null: 390,011 / 390,011\n",
      "    RoundNumber unique values ìƒ˜í”Œ: [ 2  1  3  6  7  4  8  5  9 10]\n",
      "  - company_df ì»¬ëŸ¼: comnation ì¡´ì¬ ì—¬ë¶€ = True\n",
      "    comnation unique values ìƒ˜í”Œ: ['US']\n",
      "Categories (1, object): ['US']\n",
      "    US companies: 0\n",
      "\n",
      "ğŸ“Š New Venture Funding Demand ê³„ì‚° ê²°ê³¼:\n",
      "  - ìƒì„±ëœ ë°ì´í„° í–‰ ìˆ˜: 53\n",
      "  - ì—°ë„ ë²”ìœ„: 1970 - 2022\n",
      "  - new_venture_demand ìƒ˜í”Œ:\n",
      "   year  new_venture_demand\n",
      "0  1970            2.397895\n",
      "1  1971            2.995732\n",
      "2  1972            3.332205\n",
      "3  1973            3.555348\n",
      "4  1974            3.258097\n",
      "5  1975            3.218876\n",
      "6  1976            3.583519\n",
      "7  1977            3.871201\n",
      "8  1978            4.430817\n",
      "9  1979            4.779123\n",
      "\n",
      "âœ… ë³€ìˆ˜ ìƒì„± ì™„ë£Œ\n",
      "   - ì´ í–‰ ìˆ˜: 68,045\n",
      "   - Firm ìˆ˜: 12,069\n",
      "   - ì—°ë„ ë²”ìœ„: 1970 ~ 2022\n",
      "   - ìƒì„± ë³€ìˆ˜: 12ê°œ (firmname, year ì œì™¸)\n",
      "\n",
      "ğŸ“Š ë¶„ì„ ê¸°ê°„ í•„í„°ë§ (1980~2022)\n",
      "   - í•„í„°ë§ ì „: 68,045 rows\n",
      "   - í•„í„°ë§ í›„: 67,027 rows\n",
      "   - Firm ìˆ˜: 12,013\n",
      "\n",
      "ğŸ“ˆ ê¸°ìˆ  í†µê³„:\n",
      "            firmage  industry_blau      perf_all  early_stage_ratio  \\\n",
      "count  67026.000000   67027.000000  67027.000000       67027.000000   \n",
      "mean      11.117522       0.265729      0.111880           0.296931   \n",
      "std       10.665431       0.298139      0.562375           0.375094   \n",
      "min        0.000000       0.000000      0.000000           0.000000   \n",
      "25%        3.000000       0.000000      0.000000           0.000000   \n",
      "50%        8.000000       0.000000      0.000000           0.000000   \n",
      "75%       16.000000       0.500000      0.000000           0.500000   \n",
      "max       60.000000       0.887039     26.000000           1.000000   \n",
      "\n",
      "            inv_amt       inv_num  \n",
      "count  6.702700e+04  67027.000000  \n",
      "mean   1.022972e+05      5.776538  \n",
      "std    5.049816e+05     10.662188  \n",
      "min    0.000000e+00      1.000000  \n",
      "25%    1.290000e+03      1.000000  \n",
      "50%    1.300000e+04      2.000000  \n",
      "75%    5.669200e+04      6.000000  \n",
      "max    3.951850e+07    327.000000  \n",
      "\n",
      "ìƒ˜í”Œ (ìƒìœ„ 5ê°œ):\n",
      "                            firmname  year  firmage  industry_blau  perf_IPO  \\\n",
      "1018    Citicorp Venture Capital Ltd  1984     16.0       0.789485         0   \n",
      "1019                     Vista Group  1983      3.0       0.765000         0   \n",
      "1020  Summacrest Fiduciary Trust Inc  1984      0.0       0.000000         0   \n",
      "1021            Quidnet Capital Corp  1981      6.0       0.444444         0   \n",
      "1022             Adler & Company Inc  1984     19.0       0.825069         1   \n",
      "\n",
      "      perf_MnA  perf_all  early_stage_ratio   inv_amt  inv_num  firm_hq_CA  \\\n",
      "1018         0         0           0.263158  253326.0       76         0.0   \n",
      "1019         0         0           0.571429   83787.0       21         0.0   \n",
      "1020         0         0           1.000000     500.0        1         0.0   \n",
      "1021         0         0           0.333333    3450.0        3         0.0   \n",
      "1022         0         1           0.400000  271575.0       75         0.0   \n",
      "\n",
      "      firm_hq_MA  firm_hq_NY  firm_hq  \n",
      "1018         0.0         1.0      0.0  \n",
      "1019         0.0         0.0      0.0  \n",
      "1020         0.0         0.0      0.0  \n",
      "1021         0.0         0.0      0.0  \n",
      "1022         0.0         1.0      0.0  \n",
      "\n",
      "âœ… Firm-Level ê¸°ë³¸ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ!\n",
      "   - ë°ì´í„°ì…‹: firm_vars_df_filtered\n",
      "   - Shape: (67027, 14)\n",
      "\n",
      "================================================================================\n",
      "Geographic Distance ê³„ì‚° (ZIP ì½”ë“œ ê¸°ë°˜)\n",
      "================================================================================\n",
      "\n",
      "ğŸ”„ Geographic Distance ê³„ì‚° ì¤‘...\n",
      "   - VC-Company ê±°ë¦¬ (firm-year level)\n",
      "   - VC-Co-Partner ê±°ë¦¬ (firm-year level)\n",
      "\n",
      "âœ… Geographic Distance ê³„ì‚° ì™„ë£Œ\n",
      "   - VC-Company: 68045 firm-year observations\n",
      "   - VC-Co-Partner: 52672 firm-year observations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Firm-Level ê¸°ë³¸ ë³€ìˆ˜ ìƒì„± (Firm-Year ê¸°ì¤€)\n",
    "================================================================================\n",
    "\n",
    "ìƒì„± ë³€ìˆ˜:\n",
    "----------\n",
    "1. firmage: íŒ ì—°ë ¹ (year - founding_year)\n",
    "2. industry_blau: íˆ¬ì ë‹¤ì–‘ì„± (Blau index by company industry)\n",
    "3. perf_IPO: IPO ì„±ê³¼ (sum of ipoExit)\n",
    "4. perf_MnA: M&A ì„±ê³¼ (sum of MnAExit)\n",
    "5. perf_all: ì „ì²´ ì„±ê³¼ (perf_IPO + perf_MnA)\n",
    "6. early_stage_ratio: Early stage íˆ¬ì ë¹„ìœ¨ (Seed, Series A, B)\n",
    "7. firm_hq_CAMA: ë³¸ì‚¬ ìœ„ì¹˜ ë”ë¯¸ (CA/MA = 1, else = 0)\n",
    "8. inv_amt: ì—°ê°„ ì´ íˆ¬ì ê¸ˆì•¡ (thousands)\n",
    "9. inv_num: ì—°ê°„ ì´ íˆ¬ì ê±´ìˆ˜\n",
    "\n",
    "ë°ì´í„° êµ¬ì¡°:\n",
    "-----------\n",
    "- Level: Firm-Year\n",
    "- Key: (firmname, year)\n",
    "- ë¶„ì„ ê¸°ê°„: START_YEAR ~ END_YEAR\n",
    "\"\"\"\n",
    "\n",
    "from vc_analysis.variables import firm_variables\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Firm-Level ê¸°ë³¸ ë³€ìˆ˜ ìƒì„±\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ê¸°ë³¸ ë³€ìˆ˜ ìƒì„± (firm-year ê¸°ì¤€)\n",
    "print(f\"\\nğŸ”„ ë³€ìˆ˜ ìƒì„± ì¤‘...\")\n",
    "print(f\"   - ë¶„ì„ ê¸°ê°„: {START_YEAR} ~ {END_YEAR}\")\n",
    "print(f\"   - ìƒì„± ë³€ìˆ˜: 9ê°œ\")\n",
    "\n",
    "firm_vars_df = firm_variables.calculate_all_firm_variables(\n",
    "    round_df=data['round'],\n",
    "    company_df=data['company'],\n",
    "    firm_df=data['firm'],\n",
    "    year_col='year'\n",
    ")\n",
    "\n",
    "# VC Reputation ê³„ì‚°\n",
    "reputation_df = firm_variables.calculate_vc_reputation(\n",
    "    round_df=data['round'],\n",
    "    company_df=data['company'],\n",
    "    fund_df=data['fund'],\n",
    "    year_col='year',\n",
    "    window_years=5\n",
    ")\n",
    "\n",
    "# Market Heat ê³„ì‚° (industry-level)\n",
    "market_heat_df = firm_variables.calculate_market_heat(\n",
    "    fund_df=data['fund'],\n",
    "    year_col='year',\n",
    "    fundyear_col='fundyear',\n",
    "    fundname_col='fundname'\n",
    ")\n",
    "\n",
    "# New Venture Funding Demand ê³„ì‚° (industry-level, current year)\n",
    "# ë¨¼ì € í•„ìš”í•œ ì»¬ëŸ¼ í™•ì¸\n",
    "print(\"ğŸ” New Venture Funding Demand ê³„ì‚° ì „ ì»¬ëŸ¼ í™•ì¸:\")\n",
    "print(f\"  - round_df ì»¬ëŸ¼: RoundNumber ì¡´ì¬ ì—¬ë¶€ = {'RoundNumber' in data['round'].columns}\")\n",
    "if 'RoundNumber' in data['round'].columns:\n",
    "    print(f\"    RoundNumber non-null: {data['round']['RoundNumber'].notna().sum():,} / {len(data['round']):,}\")\n",
    "    print(f\"    RoundNumber unique values ìƒ˜í”Œ: {data['round']['RoundNumber'].dropna().unique()[:10]}\")\n",
    "print(f\"  - company_df ì»¬ëŸ¼: comnation ì¡´ì¬ ì—¬ë¶€ = {'comnation' in data['company'].columns}\")\n",
    "if 'comnation' in data['company'].columns:\n",
    "    print(f\"    comnation unique values ìƒ˜í”Œ: {data['company']['comnation'].dropna().unique()[:10]}\")\n",
    "    print(f\"    US companies: {(data['company']['comnation'] == 'United States').sum():,}\")\n",
    "\n",
    "new_venture_demand_df = firm_variables.calculate_new_venture_funding_demand(\n",
    "    round_df=data['round'],\n",
    "    company_df=data['company'],\n",
    "    year_col='year',\n",
    "    roundnumber_col='RoundNumber',\n",
    "    comname_col='comname',\n",
    "    comnation_col='comnation',\n",
    "    us_nation='US'  # ë¯¸êµ­ì€ 'US'ë¡œ í‘œê¸°ë¨ (company ë°ì´í„°ì—ì„œ)\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(f\"\\nğŸ“Š New Venture Funding Demand ê³„ì‚° ê²°ê³¼:\")\n",
    "print(f\"  - ìƒì„±ëœ ë°ì´í„° í–‰ ìˆ˜: {len(new_venture_demand_df)}\")\n",
    "if len(new_venture_demand_df) > 0:\n",
    "    print(f\"  - ì—°ë„ ë²”ìœ„: {new_venture_demand_df['year'].min()} - {new_venture_demand_df['year'].max()}\")\n",
    "    print(f\"  - new_venture_demand ìƒ˜í”Œ:\")\n",
    "    print(new_venture_demand_df.head(10))\n",
    "else:\n",
    "    print(f\"  âš ï¸  ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# Zero-fill perf_* only (post-merge)\n",
    "from vc_analysis.variables.firm_variables import fill_missing_performance_with_zero\n",
    "\n",
    "firm_vars_df = fill_missing_performance_with_zero(\n",
    "    firm_vars_df,\n",
    "    columns=['perf_IPO', 'perf_MnA', 'perf_all'],\n",
    "    inplace=False\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… ë³€ìˆ˜ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì´ í–‰ ìˆ˜: {len(firm_vars_df):,}\")\n",
    "print(f\"   - Firm ìˆ˜: {firm_vars_df['firmname'].nunique():,}\")\n",
    "print(f\"   - ì—°ë„ ë²”ìœ„: {firm_vars_df['year'].min():.0f} ~ {firm_vars_df['year'].max():.0f}\")\n",
    "print(f\"   - ìƒì„± ë³€ìˆ˜: {len(firm_vars_df.columns) - 2}ê°œ (firmname, year ì œì™¸)\")\n",
    "\n",
    "# ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "firm_vars_df_filtered = firm_vars_df[\n",
    "    firm_vars_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "print(f\"\\nğŸ“Š ë¶„ì„ ê¸°ê°„ í•„í„°ë§ ({START_YEAR}~{END_YEAR})\")\n",
    "print(f\"   - í•„í„°ë§ ì „: {len(firm_vars_df):,} rows\")\n",
    "print(f\"   - í•„í„°ë§ í›„: {len(firm_vars_df_filtered):,} rows\")\n",
    "print(f\"   - Firm ìˆ˜: {firm_vars_df_filtered['firmname'].nunique():,}\")\n",
    "\n",
    "# ê¸°ìˆ  í†µê³„\n",
    "print(f\"\\nğŸ“ˆ ê¸°ìˆ  í†µê³„:\")\n",
    "desc_cols = ['firmage', 'industry_blau', 'perf_all', 'early_stage_ratio', \n",
    "             'inv_amt', 'inv_num']\n",
    "print(firm_vars_df_filtered[desc_cols].describe())\n",
    "\n",
    "print(f\"\\nìƒ˜í”Œ (ìƒìœ„ 5ê°œ):\")\n",
    "print(firm_vars_df_filtered.head())\n",
    "\n",
    "print(f\"\\nâœ… Firm-Level ê¸°ë³¸ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ!\")\n",
    "print(f\"   - ë°ì´í„°ì…‹: firm_vars_df_filtered\")\n",
    "print(f\"   - Shape: {firm_vars_df_filtered.shape}\")\n",
    "\n",
    "# Geographic Distance ê³„ì‚° (VC-Company, VC-Co-Partner)\n",
    "from vc_analysis.distance import geographic\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Geographic Distance ê³„ì‚° (ZIP ì½”ë“œ ê¸°ë°˜)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ”„ Geographic Distance ê³„ì‚° ì¤‘...\")\n",
    "print(\"   - VC-Company ê±°ë¦¬ (firm-year level)\")\n",
    "print(\"   - VC-Co-Partner ê±°ë¦¬ (firm-year level)\")\n",
    "\n",
    "# ZIP code database êµ¬ì¶• (í•œ ë²ˆë§Œ)\n",
    "zipcode_db = geographic.build_zipcode_database(\n",
    "    firm_df=data['firm'],\n",
    "    company_df=data['company'],\n",
    "    firmzip_col='firmzip',\n",
    "    comzip_col='comzip'\n",
    ")\n",
    "\n",
    "# 1) VC-Company ê±°ë¦¬ ê³„ì‚°\n",
    "geo_dist_company_df = geographic.calculate_vc_company_distances(\n",
    "    round_df=data['round'],\n",
    "    firm_df=data['firm'],\n",
    "    company_df=data['company'],\n",
    "    zipcode_db=zipcode_db,\n",
    "    firm_col='firmname',\n",
    "    comname_col='comname',\n",
    "    year_col='year',\n",
    "    firmzip_col='firmzip',\n",
    "    comzip_col='comzip',\n",
    "    amount_col='RoundAmountDisclosedThou'  # ê°€ì¤‘ í‰ê· ìš©\n",
    ")\n",
    "\n",
    "# 2) VC-Co-Partner ê±°ë¦¬ ê³„ì‚°\n",
    "geo_dist_copartner_df = geographic.calculate_vc_copartner_distances(\n",
    "    round_df=data['round'],\n",
    "    firm_df=data['firm'],\n",
    "    zipcode_db=zipcode_db,\n",
    "    firm_col='firmname',\n",
    "    comname_col='comname',\n",
    "    year_col='year',\n",
    "    firmzip_col='firmzip',\n",
    "    amount_col='RoundAmountDisclosedThou'  # ê°€ì¤‘ í‰ê· ìš©\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Geographic Distance ê³„ì‚° ì™„ë£Œ\")\n",
    "print(f\"   - VC-Company: {len(geo_dist_company_df)} firm-year observations\")\n",
    "print(f\"   - VC-Co-Partner: {len(geo_dist_copartner_df)} firm-year observations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0629aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±: Firm-Year ê¸°ì¤€ Merge\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Step 1: ê¸°ì¤€ ë°ì´í„° ì¤€ë¹„\n",
      "   - ê¸°ì¤€: firm_vars_df_filtered (íˆ¬ì ì§‘í–‰ firm-year)\n",
      "   - ê¸°ê°„: 1980 ~ 2022\n",
      "   - Shape: (67027, 14)\n",
      "   - Firm ìˆ˜: 12,013\n",
      "   - ê¸°ë³¸ ë³€ìˆ˜: ['firmage', 'industry_blau', 'perf_IPO', 'perf_MnA', 'perf_all', 'early_stage_ratio', 'inv_amt', 'inv_num', 'firm_hq_CA', 'firm_hq_MA', 'firm_hq_NY', 'firm_hq']\n",
      "\n",
      "ğŸ“Š Step 2: Network Centrality Merge\n",
      "   - Merge ë°©ë²•: Left join on (firmname, year)\n",
      "   - ê¸°ì¤€ rows: 67,027 (íˆ¬ì ì§‘í–‰ firm-year)\n",
      "   - Centrality rows: 99,737 (ë„¤íŠ¸ì›Œí¬ ë“±ì¥ firm-year)\n",
      "   - ìµœì¢… Shape: (67027, 22)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 8ê°œ (ì¤‘ì‹¬ì„±)\n",
      "\n",
      "   âš ï¸  Centrality Missing ë°œê²¬ (ë„¤íŠ¸ì›Œí¬ ë¯¸ë“±ì¥):\n",
      "      - dgr_cent: 14,324 (21.4%)\n",
      "      - btw_cent: 14,324 (21.4%)\n",
      "      - pwr_max: 14,324 (21.4%)\n",
      "      - pwr_p0: 14,324 (21.4%)\n",
      "      - pwr_p75: 14,324 (21.4%)\n",
      "      - pwr_p99: 14,324 (21.4%)\n",
      "      - constraint: 14,324 (21.4%)\n",
      "      - ego_dens: 14,324 (21.4%)\n",
      "\n",
      "ğŸ“Š Step 3: Initial Period Variables ê³„ì‚° (t1~t3)\n",
      "   - market_heat_df_filtered: 1980 ~ 2022 (43ë…„)\n",
      "   - new_venture_demand_df_filtered: 1980 ~ 2022 (43ë…„)\n",
      "   - ìƒì„±ëœ ë³€ìˆ˜: 8ê°œ\n",
      "   - ë³€ìˆ˜ ëª©ë¡:\n",
      "      - initial_year: 11,296 non-null (100.0%)\n",
      "      - initial_early_stage_ratio: 11,296 non-null (100.0%)\n",
      "      - initial_industry_blau: 11,296 non-null (100.0%)\n",
      "      - initial_inv_num: 11,296 non-null (100.0%)\n",
      "      - initial_inv_amt: 11,296 non-null (100.0%)\n",
      "      - initial_firmage: 11,296 non-null (100.0%)\n",
      "      - initial_market_heat: 11,296 non-null (100.0%)\n",
      "      - initial_new_venture_demand: 11,296 non-null (100.0%)\n",
      "\n",
      "ğŸ”„ Initial Period Geographic Distance ê³„ì‚° ì¤‘...\n",
      "   - ìƒì„±ëœ ë³€ìˆ˜: 5ê°œ\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±: Firm-Year ê¸°ì¤€ Merge\n",
    "================================================================================\n",
    "\n",
    "Merge ì „ëµ:\n",
    "----------\n",
    "1. ê¸°ì¤€ ë°ì´í„°: centrality_df (firm-year ì¤‘ì‹¬ì„± ë°ì´í„°)\n",
    "   - Key: (firmname, year)\n",
    "   - ë¶„ì„ ê¸°ê°„: START_YEAR ~ END_YEAR\n",
    "   \n",
    "2. Merge ë°ì´í„°:\n",
    "   a) firm_vars_df_filtered: Firm-level ê¸°ë³¸ ë³€ìˆ˜ (firm-year)\n",
    "   b) initial_ties_df: Initial partner íŠ¹ì„± (firm-level, initial_yearë¡œ ë§¤ì¹­)\n",
    "   c) reputation_df: VC Reputation ë³€ìˆ˜ (firm-year)\n",
    "\n",
    "3. Merge ë°©ë²•:\n",
    "   - Left join: firm_vars_df_filteredë¥¼ ê¸°ì¤€ìœ¼ë¡œ\n",
    "   - firm_vars: (firmname, year) ë§¤ì¹­\n",
    "   - initial_ties: firmname ë§¤ì¹­ (initial_yearëŠ” ì •ë³´ ë³€ìˆ˜ë¡œ ìœ ì§€)\n",
    "   - reputation: (firmname, year) ë§¤ì¹­\n",
    "\n",
    "ìµœì¢… ë°ì´í„° êµ¬ì¡°:\n",
    "---------------\n",
    "- Level: Firm-Year\n",
    "- Key: (firmname, year)\n",
    "- ë³€ìˆ˜ ê·¸ë£¹:\n",
    "  * Network centrality (8ê°œ): dgr_cent, btw_cent, pwr_*, constraint, ego_dens\n",
    "  * Firm basics (9ê°œ): firmage, industry_blau, perf_*, early_stage_ratio, firm_hq, inv_amt, inv_num\n",
    "  * Initial partner status (24ê°œ): initial_*_mean/max/min for each centrality\n",
    "  * VC Reputation (7ê°œ): rep_portfolio_count, rep_total_invested, rep_avg_fum, rep_funds_raised, rep_ipos, fundingAge, VC_reputation\n",
    "  * Meta info: initial_year, n_initial_partners, n_partner_years\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ìµœì¢… ë°ì´í„°ì…‹ ìƒì„±: Firm-Year ê¸°ì¤€ Merge\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Step 1: ê¸°ì¤€ ë°ì´í„° ì¤€ë¹„ (Firm Variables - R ì½”ë“œ ë¡œì§)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 1: ê¸°ì¤€ ë°ì´í„° ì¤€ë¹„\")\n",
    "\n",
    "print(f\"   - ê¸°ì¤€: firm_vars_df_filtered (íˆ¬ì ì§‘í–‰ firm-year)\")\n",
    "print(f\"   - ê¸°ê°„: {START_YEAR} ~ {END_YEAR}\")\n",
    "print(f\"   - Shape: {firm_vars_df_filtered.shape}\")\n",
    "print(f\"   - Firm ìˆ˜: {firm_vars_df_filtered['firmname'].nunique():,}\")\n",
    "print(f\"   - ê¸°ë³¸ ë³€ìˆ˜: {[col for col in firm_vars_df_filtered.columns if col not in ['firmname', 'year']]}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 2: Network Centrality Merge (R ì½”ë“œ: left_join(dta, cent_1y))\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 2: Network Centrality Merge\")\n",
    "\n",
    "# Centrality ë°ì´í„°ë¥¼ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "centrality_df_filtered = centrality_df[\n",
    "    centrality_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "# R ì½”ë“œ ë¡œì§: firm_varsë¥¼ ê¸°ì¤€ìœ¼ë¡œ centralityë¥¼ left join\n",
    "final_df = firm_vars_df_filtered.merge(\n",
    "    centrality_df_filtered,\n",
    "    on=['firmname', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on (firmname, year)\")\n",
    "print(f\"   - ê¸°ì¤€ rows: {len(firm_vars_df_filtered):,} (íˆ¬ì ì§‘í–‰ firm-year)\")\n",
    "print(f\"   - Centrality rows: {len(centrality_df_filtered):,} (ë„¤íŠ¸ì›Œí¬ ë“±ì¥ firm-year)\")\n",
    "print(f\"   - ìµœì¢… Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len(centrality_df_filtered.columns) - 2}ê°œ (ì¤‘ì‹¬ì„±)\")\n",
    "\n",
    "# Missing ì²´í¬ (Centrality ë³€ìˆ˜)\n",
    "centrality_cols = [col for col in centrality_df_filtered.columns if col not in ['firmname', 'year']]\n",
    "missing_counts = final_df[centrality_cols].isnull().sum()\n",
    "if missing_counts.sum() > 0:\n",
    "    print(f\"\\n   âš ï¸  Centrality Missing ë°œê²¬ (ë„¤íŠ¸ì›Œí¬ ë¯¸ë“±ì¥):\")\n",
    "    for col, count in missing_counts[missing_counts > 0].items():\n",
    "        print(f\"      - {col}: {count:,} ({count/len(final_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   âœ… Centrality Missing ì—†ìŒ (ëª¨ë“  firmì´ ë„¤íŠ¸ì›Œí¬ì— ë“±ì¥)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 3: Initial Period Variables ê³„ì‚° (t1~t3 ê¸°ê°„ ë³€ìˆ˜ ì§‘ê³„)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 3: Initial Period Variables ê³„ì‚° (t1~t3)\")\n",
    "\n",
    "from vc_analysis.network import imprinting\n",
    "\n",
    "# ë¶„ì„ ê¸°ê°„ í•„í„°ë§ (market_heat_df, new_venture_demand_df)\n",
    "market_heat_df_filtered = market_heat_df[\n",
    "    market_heat_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "new_venture_demand_df_filtered = new_venture_demand_df[\n",
    "    new_venture_demand_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "print(f\"   - market_heat_df_filtered: {market_heat_df_filtered['year'].min()} ~ {market_heat_df_filtered['year'].max()} ({len(market_heat_df_filtered)}ë…„)\")\n",
    "print(f\"   - new_venture_demand_df_filtered: {new_venture_demand_df_filtered['year'].min()} ~ {new_venture_demand_df_filtered['year'].max()} ({len(new_venture_demand_df_filtered)}ë…„)\")\n",
    "\n",
    "# Initial period ë³€ìˆ˜ ê³„ì‚° (t1~t3 ê¸°ê°„ ë™ì•ˆì˜ íˆ¬ì í–‰ìœ„/íŠ¹ì„± ì§‘ê³„)\n",
    "initial_period_vars_df = imprinting.calculate_initial_period_variables(\n",
    "    initial_year_df=initial_year_df,\n",
    "    firm_vars_df=firm_vars_df_filtered,  # ë¶„ì„ ê¸°ê°„ í•„í„°ë§ëœ firm-year ë³€ìˆ˜\n",
    "    market_heat_df=market_heat_df_filtered if 'market_heat_df_filtered' in locals() else None,\n",
    "    new_venture_demand_df=new_venture_demand_df_filtered if 'new_venture_demand_df_filtered' in locals() else None,\n",
    "    imprinting_period=3,  # t1~t3 (3ë…„)\n",
    "    firm_col='firmname',\n",
    "    year_col='year'\n",
    ")\n",
    "\n",
    "print(f\"   - ìƒì„±ëœ ë³€ìˆ˜: {len([c for c in initial_period_vars_df.columns if c.startswith('initial_')])}ê°œ\")\n",
    "print(f\"   - ë³€ìˆ˜ ëª©ë¡:\")\n",
    "for col in initial_period_vars_df.columns:\n",
    "    if col.startswith('initial_'):\n",
    "        non_null = initial_period_vars_df[col].notna().sum()\n",
    "        print(f\"      - {col}: {non_null:,} non-null ({non_null/len(initial_period_vars_df)*100:.1f}%)\")\n",
    "\n",
    "# Initial period geographic distance ê³„ì‚° (t1~t3 ê¸°ê°„ ë™ì•ˆì˜ ê³µë™ íˆ¬ì íŒŒíŠ¸ë„ˆ ê±°ë¦¬)\n",
    "print(\"\\nğŸ”„ Initial Period Geographic Distance ê³„ì‚° ì¤‘...\")\n",
    "initial_geo_dist_df = imprinting.calculate_initial_period_geographic_distances(\n",
    "    initial_year_df=initial_year_df,\n",
    "    copartner_dist_df=geo_dist_copartner_df,  # ì „ì²´ ê¸°ê°„ co-partner ê±°ë¦¬ ë°ì´í„°\n",
    "    imprinting_period=3,  # t1~t3 (3ë…„)\n",
    "    firm_col='firmname',\n",
    "    year_col='year'\n",
    ")\n",
    "\n",
    "print(f\"   - ìƒì„±ëœ ë³€ìˆ˜: {len([c for c in initial_geo_dist_df.columns if c.startswith('initial_geo_dist_copartner')])}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3da3c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Step 4: Initial Partner Status Merge\n",
      "   - Merge ë°©ë²•: Left join on firmname\n",
      "   - Shape: (67027, 49)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 27ê°œ\n",
      "\n",
      "ğŸ“Š Step 4-1: Initial Period Variables Merge (t1~t3)\n",
      "   - Merge ë°©ë²•: Left join on firmname\n",
      "   - Shape: (67027, 56)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 8ê°œ\n",
      "   - ë³€ìˆ˜ ëª©ë¡:\n",
      "      - initial_early_stage_ratio: 61,497 non-null (91.7%)\n",
      "      - initial_industry_blau: 61,497 non-null (91.7%)\n",
      "      - initial_inv_num: 61,497 non-null (91.7%)\n",
      "      - initial_inv_amt: 61,497 non-null (91.7%)\n",
      "      - initial_firmage: 61,497 non-null (91.7%)\n",
      "      - initial_market_heat: 61,497 non-null (91.7%)\n",
      "      - initial_new_venture_demand: 61,497 non-null (91.7%)\n",
      "\n",
      "ğŸ“Š Step 4-2: Initial Period Geographic Distance Merge (t1~t3)\n",
      "   - Merge ë°©ë²•: Left join on firmname\n",
      "   - Shape: (67027, 61)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 5ê°œ\n",
      "   - ë³€ìˆ˜ ëª©ë¡:\n",
      "      - initial_geo_dist_copartner_mean: 51,047 non-null (76.2%)\n",
      "      - initial_geo_dist_copartner_min: 51,047 non-null (76.2%)\n",
      "      - initial_geo_dist_copartner_max: 51,047 non-null (76.2%)\n",
      "      - initial_geo_dist_copartner_std: 45,428 non-null (67.8%)\n",
      "      - initial_geo_dist_copartner_weighted_mean: 51,047 non-null (76.2%)\n",
      "\n",
      "   ğŸ“ˆ Initial Ties ë§¤ì¹­ í˜„í™©:\n",
      "      - ë§¤ì¹­ëœ firm-year: 49,133 (73.3%)\n",
      "      - ë§¤ì¹­ ì•ˆ ëœ firm-year: 17,894 (26.7%)\n",
      "      - Unique firm (ë§¤ì¹­): 8,276\n",
      "      - Unique firm (ì „ì²´): 12,013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Step 4: Initial Partner Status Merge (R ì½”ë“œ: left_join(dta, initial_partner))\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 4: Initial Partner Status Merge\")\n",
    "\n",
    "# initial_ties_dfì—ì„œ ì¤‘ë³µ ì œê±° (firmname ê¸°ì¤€)\n",
    "# initial_yearëŠ” ê° firmë§ˆë‹¤ í•˜ë‚˜ë§Œ ì¡´ì¬í•´ì•¼ í•¨\n",
    "if initial_ties_df['firmname'].duplicated().any():\n",
    "    print(f\"   âš ï¸  ì¤‘ë³µ firmname ë°œê²¬: {initial_ties_df['firmname'].duplicated().sum()}ê°œ\")\n",
    "    print(f\"   â†’ ì²« ë²ˆì§¸ í–‰ë§Œ ìœ ì§€\")\n",
    "    initial_ties_df_unique = initial_ties_df.drop_duplicates(subset=['firmname'], keep='first')\n",
    "else:\n",
    "    initial_ties_df_unique = initial_ties_df\n",
    "\n",
    "final_df = final_df.merge(\n",
    "    initial_ties_df_unique,\n",
    "    on='firmname',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on firmname\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len(initial_ties_df_unique.columns) - 1}ê°œ\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4-1: Initial Period Variables Merge (t1~t3 ê¸°ê°„ ë³€ìˆ˜)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 4-1: Initial Period Variables Merge (t1~t3)\")\n",
    "\n",
    "# Remove 'initial_year' from initial_period_vars_df before merge to avoid _x/_y suffix\n",
    "initial_period_vars_df_clean = initial_period_vars_df.drop(columns=['initial_year'], errors='ignore').copy()\n",
    "\n",
    "final_df = final_df.merge(\n",
    "    initial_period_vars_df_clean,\n",
    "    on='firmname',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on firmname\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len([c for c in initial_period_vars_df.columns if c.startswith('initial_')])}ê°œ\")\n",
    "print(f\"   - ë³€ìˆ˜ ëª©ë¡:\")\n",
    "for col in initial_period_vars_df.columns:\n",
    "    if col.startswith('initial_') and col != 'initial_year':\n",
    "        non_null = final_df[col].notna().sum()\n",
    "        print(f\"      - {col}: {non_null:,} non-null ({non_null/len(final_df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 4-2: Initial Period Geographic Distance Merge (t1~t3 ê¸°ê°„ ê³µë™ íˆ¬ì íŒŒíŠ¸ë„ˆ ê±°ë¦¬)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 4-2: Initial Period Geographic Distance Merge (t1~t3)\")\n",
    "\n",
    "# Remove 'initial_year' from initial_geo_dist_df before merge to avoid _x/_y suffix\n",
    "initial_geo_dist_df_clean = initial_geo_dist_df.drop(columns=['initial_year'], errors='ignore').copy()\n",
    "\n",
    "final_df = final_df.merge(\n",
    "    initial_geo_dist_df_clean,\n",
    "    on='firmname',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on firmname\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len([c for c in initial_geo_dist_df.columns if c.startswith('initial_geo_dist_copartner')])}ê°œ\")\n",
    "print(f\"   - ë³€ìˆ˜ ëª©ë¡:\")\n",
    "for col in initial_geo_dist_df.columns:\n",
    "    if col.startswith('initial_geo_dist_copartner'):\n",
    "        non_null = final_df[col].notna().sum()\n",
    "        print(f\"      - {col}: {non_null:,} non-null ({non_null/len(final_df)*100:.1f}%)\")\n",
    "\n",
    "# Initial tiesê°€ ìˆëŠ” firm ë¹„ìœ¨\n",
    "has_initial_ties = final_df['initial_year'].notna()\n",
    "matched_count = int(has_initial_ties.sum())\n",
    "unmatched_count = int((~has_initial_ties).sum())\n",
    "print(f\"\\n   ğŸ“ˆ Initial Ties ë§¤ì¹­ í˜„í™©:\")\n",
    "print(f\"      - ë§¤ì¹­ëœ firm-year: {matched_count:,} ({matched_count/len(final_df)*100:.1f}%)\")\n",
    "print(f\"      - ë§¤ì¹­ ì•ˆ ëœ firm-year: {unmatched_count:,} ({unmatched_count/len(final_df)*100:.1f}%)\")\n",
    "print(f\"      - Unique firm (ë§¤ì¹­): {final_df[has_initial_ties]['firmname'].nunique():,}\")\n",
    "print(f\"      - Unique firm (ì „ì²´): {final_df['firmname'].nunique():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35d0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Step 5: Geographic Distance Merge\n",
      "   - VC-Company ê±°ë¦¬ Merge: Left join on (firmname, year)\n",
      "   - Shape: (67027, 66)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 5ê°œ\n",
      "   - VC-Co-Partner ê±°ë¦¬ Merge: Left join on (firmname, year)\n",
      "   - Shape: (67027, 71)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 5ê°œ\n",
      "\n",
      "   âš ï¸  VC-Company Distance Missing:\n",
      "      - geo_dist_company_mean: 7,885 (11.8%)\n",
      "      - geo_dist_company_min: 7,885 (11.8%)\n",
      "      - geo_dist_company_max: 7,885 (11.8%)\n",
      "      - geo_dist_company_std: 29,573 (44.1%)\n",
      "      - geo_dist_company_weighted_mean: 18,395 (27.4%)\n",
      "\n",
      "   âš ï¸  VC-Co-Partner Distance Missing:\n",
      "      - geo_dist_copartner_mean: 15,074 (22.5%)\n",
      "      - geo_dist_copartner_min: 15,074 (22.5%)\n",
      "      - geo_dist_copartner_max: 15,074 (22.5%)\n",
      "      - geo_dist_copartner_std: 21,716 (32.4%)\n",
      "      - geo_dist_copartner_weighted_mean: 15,074 (22.5%)\n",
      "\n",
      "ğŸ“Š Step 6: VC Reputation Merge\n",
      "   - Merge ë°©ë²•: Left join on (firmname, year)\n",
      "   - Shape: (67027, 86)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 15ê°œ (VC Reputation)\n",
      "   - Reputation ë³€ìˆ˜: ['rep_portfolio_count', 'rep_total_invested', 'rep_avg_fum', 'rep_funds_raised', 'rep_ipos', 'fundingAge', 'rep_missing_fund_data', 'rep_portfolio_count_z', 'rep_total_invested_z', 'rep_avg_fum_z', 'rep_funds_raised_z', 'rep_ipos_z', 'rep_index_raw', 'VC_reputation']\n",
      "   âœ… Reputation Missing ì—†ìŒ\n",
      "\n",
      "ğŸ“Š Step 7: Market Heat Merge (Industry-Level, Current Year)\n",
      "   - Merge ë°©ë²•: Left join on year (industry-level)\n",
      "   - Shape: (67027, 87)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 1ê°œ (market_heat)\n",
      "   âœ… Market Heat Missing ì—†ìŒ\n",
      "\n",
      "   ğŸ“ˆ Market Heat ê¸°ìˆ  í†µê³„:\n",
      "      - ë²”ìœ„: -0.772 ~ 0.792\n",
      "      - í‰ê· : 0.125\n",
      "      - Hot markets (>0): 46,389 (69.2%)\n",
      "      - Cold markets (<0): 20,638 (30.8%)\n",
      "\n",
      "ğŸ“Š Step 8: New Venture Funding Demand Merge (Industry-Level, Current Year)\n",
      "   - Merge ë°©ë²•: Left join on year (industry-level)\n",
      "   - Shape: (67027, 88)\n",
      "   - ì¶”ê°€ëœ ë³€ìˆ˜: 1ê°œ (new_venture_demand, current year)\n",
      "   - ì£¼ì˜: Raw ë°ì´í„°ì…‹ì´ë¯€ë¡œ ë‹¹í•´ ì—°ë„ ê¸°ì¤€. Panel ë¶„ì„ ì‹œ lagging í•„ìš”\n",
      "   âœ… New Venture Funding Demand Missing ì—†ìŒ\n",
      "\n",
      "   ğŸ“ˆ New Venture Funding Demand ê¸°ìˆ  í†µê³„:\n",
      "      - ë²”ìœ„: 5.366 ~ 8.083\n",
      "      - í‰ê· : 7.321\n",
      "      - í‘œì¤€í¸ì°¨: 0.584\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Step 5: Geographic Distance Merge (VC-Company, VC-Co-Partner)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 5: Geographic Distance Merge\")\n",
    "\n",
    "# Geographic distance ë°ì´í„°ë¥¼ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "geo_dist_company_df_filtered = geo_dist_company_df[\n",
    "    geo_dist_company_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "geo_dist_copartner_df_filtered = geo_dist_copartner_df[\n",
    "    geo_dist_copartner_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "# Merge VC-Company distances\n",
    "final_df = final_df.merge(\n",
    "    geo_dist_company_df_filtered,\n",
    "    on=['firmname', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - VC-Company ê±°ë¦¬ Merge: Left join on (firmname, year)\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len([c for c in geo_dist_company_df_filtered.columns if c.startswith('geo_dist_company')])}ê°œ\")\n",
    "\n",
    "# Merge VC-Co-Partner distances\n",
    "final_df = final_df.merge(\n",
    "    geo_dist_copartner_df_filtered,\n",
    "    on=['firmname', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - VC-Co-Partner ê±°ë¦¬ Merge: Left join on (firmname, year)\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len([c for c in geo_dist_copartner_df_filtered.columns if c.startswith('geo_dist_copartner')])}ê°œ\")\n",
    "\n",
    "# Missing ì²´í¬\n",
    "geo_company_cols = [c for c in final_df.columns if c.startswith('geo_dist_company')]\n",
    "geo_copartner_cols = [c for c in final_df.columns if c.startswith('geo_dist_copartner')]\n",
    "\n",
    "if geo_company_cols:\n",
    "    missing_company = final_df[geo_company_cols].isnull().sum()\n",
    "    if missing_company.sum() > 0:\n",
    "        print(f\"\\n   âš ï¸  VC-Company Distance Missing:\")\n",
    "        for col, count in missing_company[missing_company > 0].items():\n",
    "            print(f\"      - {col}: {count:,} ({count/len(final_df)*100:.1f}%)\")\n",
    "\n",
    "if geo_copartner_cols:\n",
    "    missing_copartner = final_df[geo_copartner_cols].isnull().sum()\n",
    "    if missing_copartner.sum() > 0:\n",
    "        print(f\"\\n   âš ï¸  VC-Co-Partner Distance Missing:\")\n",
    "        for col, count in missing_copartner[missing_copartner > 0].items():\n",
    "            print(f\"      - {col}: {count:,} ({count/len(final_df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 6: VC Reputation Merge\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 6: VC Reputation Merge\")\n",
    "\n",
    "# Reputation ë°ì´í„°ë¥¼ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "reputation_df_filtered = reputation_df[\n",
    "    reputation_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "# Merge reputation data (firm-year level)\n",
    "final_df = final_df.merge(\n",
    "    reputation_df_filtered,\n",
    "    on=['firmname', 'year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on (firmname, year)\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: {len(reputation_df_filtered.columns) - 2}ê°œ (VC Reputation)\")\n",
    "\n",
    "# Reputation ë³€ìˆ˜ í™•ì¸\n",
    "rep_vars = [col for col in final_df.columns if col.startswith('rep_') or col == 'VC_reputation' or col == 'fundingAge']\n",
    "if rep_vars:\n",
    "    print(f\"   - Reputation ë³€ìˆ˜: {rep_vars}\")\n",
    "    \n",
    "    # Missing ì²´í¬\n",
    "    rep_missing = final_df[rep_vars].isnull().sum()\n",
    "    if rep_missing.sum() > 0:\n",
    "        print(f\"\\n   âš ï¸  Reputation Missing ë°œê²¬:\")\n",
    "        for col, count in rep_missing[rep_missing > 0].items():\n",
    "            print(f\"      - {col}: {count:,} ({count/len(final_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   âœ… Reputation Missing ì—†ìŒ\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Reputation ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 7: Market Heat Merge (Industry-Level, Current Year)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 7: Market Heat Merge (Industry-Level, Current Year)\")\n",
    "\n",
    "# Market Heat ë°ì´í„°ë¥¼ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "market_heat_df_filtered = market_heat_df[\n",
    "    market_heat_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "# Merge market heat data (industry-level: ê°™ì€ ì—°ë„ë©´ ëª¨ë“  firmì— ë™ì¼í•œ ê°’)\n",
    "final_df = final_df.merge(\n",
    "    market_heat_df_filtered,\n",
    "    on='year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on year (industry-level)\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: 1ê°œ (market_heat)\")\n",
    "\n",
    "# Market Heat ë³€ìˆ˜ í™•ì¸\n",
    "if 'market_heat' in final_df.columns:\n",
    "    # Missing ì²´í¬\n",
    "    market_heat_missing = final_df['market_heat'].isnull().sum()\n",
    "    if market_heat_missing > 0:\n",
    "        print(f\"\\n   âš ï¸  Market Heat Missing ë°œê²¬:\")\n",
    "        print(f\"      - market_heat: {market_heat_missing:,} ({market_heat_missing/len(final_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   âœ… Market Heat Missing ì—†ìŒ\")\n",
    "    \n",
    "    # ê¸°ìˆ  í†µê³„\n",
    "    print(f\"\\n   ğŸ“ˆ Market Heat ê¸°ìˆ  í†µê³„:\")\n",
    "    print(f\"      - ë²”ìœ„: {final_df['market_heat'].min():.3f} ~ {final_df['market_heat'].max():.3f}\")\n",
    "    print(f\"      - í‰ê· : {final_df['market_heat'].mean():.3f}\")\n",
    "    hot_markets = (final_df['market_heat'] > 0).sum()\n",
    "    cold_markets = (final_df['market_heat'] < 0).sum()\n",
    "    print(f\"      - Hot markets (>0): {hot_markets:,} ({hot_markets/len(final_df)*100:.1f}%)\")\n",
    "    print(f\"      - Cold markets (<0): {cold_markets:,} ({cold_markets/len(final_df)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  Market Heat ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
    "\n",
    "# ============================================================================\n",
    "# Step 8: New Venture Funding Demand Merge (Industry-Level, Current Year)\n",
    "# ============================================================================\n",
    "print(\"\\nğŸ“Š Step 8: New Venture Funding Demand Merge (Industry-Level, Current Year)\")\n",
    "\n",
    "# New Venture Funding Demand ë°ì´í„°ë¥¼ ë¶„ì„ ê¸°ê°„ìœ¼ë¡œ í•„í„°ë§\n",
    "new_venture_demand_df_filtered = new_venture_demand_df[\n",
    "    new_venture_demand_df['year'].between(START_YEAR, END_YEAR)\n",
    "].copy()\n",
    "\n",
    "# Merge new venture demand data (industry-level: ê°™ì€ ì—°ë„ë©´ ëª¨ë“  firmì— ë™ì¼í•œ ê°’)\n",
    "final_df = final_df.merge(\n",
    "    new_venture_demand_df_filtered,\n",
    "    on='year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   - Merge ë°©ë²•: Left join on year (industry-level)\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - ì¶”ê°€ëœ ë³€ìˆ˜: 1ê°œ (new_venture_demand, current year)\")\n",
    "print(f\"   - ì£¼ì˜: Raw ë°ì´í„°ì…‹ì´ë¯€ë¡œ ë‹¹í•´ ì—°ë„ ê¸°ì¤€. Panel ë¶„ì„ ì‹œ lagging í•„ìš”\")\n",
    "\n",
    "# New Venture Funding Demand ë³€ìˆ˜ í™•ì¸\n",
    "if 'new_venture_demand' in final_df.columns:\n",
    "    # Missing ì²´í¬\n",
    "    demand_missing = final_df['new_venture_demand'].isnull().sum()\n",
    "    if demand_missing > 0:\n",
    "        print(f\"\\n   âš ï¸  New Venture Funding Demand Missing ë°œê²¬:\")\n",
    "        print(f\"      - new_venture_demand: {demand_missing:,} ({demand_missing/len(final_df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   âœ… New Venture Funding Demand Missing ì—†ìŒ\")\n",
    "    \n",
    "    # ê¸°ìˆ  í†µê³„\n",
    "    print(f\"\\n   ğŸ“ˆ New Venture Funding Demand ê¸°ìˆ  í†µê³„:\")\n",
    "    print(f\"      - ë²”ìœ„: {final_df['new_venture_demand'].min():.3f} ~ {final_df['new_venture_demand'].max():.3f}\")\n",
    "    print(f\"      - í‰ê· : {final_df['new_venture_demand'].mean():.3f}\")\n",
    "    print(f\"      - í‘œì¤€í¸ì°¨: {final_df['new_venture_demand'].std():.3f}\")\n",
    "else:\n",
    "    print(f\"   âš ï¸  New Venture Funding Demand ë³€ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f5e8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹: final_df\n",
      "   - Shape: (67027, 88)\n",
      "   - Level: Firm-Year\n",
      "   - Key: (firmname, year)\n",
      "   - ê¸°ê°„: 1980 ~ 2022\n",
      "   - Firm ìˆ˜: 12,013\n",
      "   - ì´ ë³€ìˆ˜: 88ê°œ (Market Heat, New Venture Funding Demand í¬í•¨)\n",
      "\n",
      "ğŸ“‹ ë³€ìˆ˜ ê·¸ë£¹:\n",
      "\n",
      "   1. Key ë³€ìˆ˜ (2ê°œ):\n",
      "      - firmname\n",
      "      - year\n",
      "\n",
      "   2. Network Centrality (8ê°œ):\n",
      "      - dgr_cent\n",
      "      - btw_cent\n",
      "      - pwr_max\n",
      "      - pwr_p0\n",
      "      - pwr_p75\n",
      "      - pwr_p99\n",
      "      - constraint\n",
      "      - ego_dens\n",
      "\n",
      "   3. Firm Basics (8ê°œ):\n",
      "      - firmage\n",
      "      - industry_blau\n",
      "      - perf_IPO\n",
      "      - perf_MnA\n",
      "      - perf_all\n",
      "      - early_stage_ratio\n",
      "      - inv_amt\n",
      "      - inv_num\n",
      "\n",
      "   4. Initial Partner Status (28ê°œ):\n",
      "      - 9ê°œ ì¤‘ì‹¬ì„± Ã— 3ê°œ ì§‘ê³„ (mean/max/min)\n",
      "      - ì˜ˆ: ['initial_dgr_cent_mean', 'initial_dgr_cent_max', 'initial_dgr_cent_min']\n",
      "\n",
      "   5. VC Reputation (14ê°œ):\n",
      "      - rep_portfolio_count\n",
      "      - rep_total_invested\n",
      "      - rep_avg_fum\n",
      "      - rep_funds_raised\n",
      "      - rep_ipos\n",
      "      - fundingAge\n",
      "      - rep_missing_fund_data\n",
      "      - rep_portfolio_count_z\n",
      "      - rep_total_invested_z\n",
      "      - rep_avg_fum_z\n",
      "      - rep_funds_raised_z\n",
      "      - rep_ipos_z\n",
      "      - rep_index_raw\n",
      "      - VC_reputation\n",
      "\n",
      "   6. Geographic Distance - VC-Company (5ê°œ):\n",
      "      - geo_dist_company_mean\n",
      "      - geo_dist_company_min\n",
      "      - geo_dist_company_max\n",
      "      - geo_dist_company_std\n",
      "      - geo_dist_company_weighted_mean\n",
      "\n",
      "   7. Geographic Distance - VC-Co-Partner (5ê°œ):\n",
      "      - geo_dist_copartner_mean\n",
      "      - geo_dist_copartner_min\n",
      "      - geo_dist_copartner_max\n",
      "      - geo_dist_copartner_std\n",
      "      - geo_dist_copartner_weighted_mean\n",
      "\n",
      "   8. Market Heat (1ê°œ):\n",
      "      - market_heat\n",
      "\n",
      "   9. New Venture Funding Demand (1ê°œ):\n",
      "      - new_venture_demand (current year, ln(count of first-round US ventures in year t))\n",
      "        â†’ Panel ë¶„ì„ ì‹œ lagging í•„ìš” (ì˜ˆ: year t-1 ì‚¬ìš©)\n",
      "\n",
      "   10. Meta Info (3ê°œ):\n",
      "      - initial_year\n",
      "      - n_initial_partners\n",
      "      - n_partner_years\n",
      "\n",
      "ğŸ“ˆ ê¸°ìˆ  í†µê³„ (ì£¼ìš” ë³€ìˆ˜):\n",
      "           dgr_cent       firmage  industry_blau      perf_all       inv_num  \\\n",
      "count  52703.000000  67026.000000   67027.000000  67027.000000  67027.000000   \n",
      "mean      28.647098     11.117522       0.265729      0.111880      5.776538   \n",
      "std       45.906986     10.665431       0.298139      0.562375     10.662188   \n",
      "min        0.000000      0.000000       0.000000      0.000000      1.000000   \n",
      "25%        3.000000      3.000000       0.000000      0.000000      1.000000   \n",
      "50%       11.000000      8.000000       0.000000      0.000000      2.000000   \n",
      "75%       35.000000     16.000000       0.500000      0.000000      6.000000   \n",
      "max      765.000000     60.000000       0.887039     26.000000    327.000000   \n",
      "\n",
      "       initial_dgr_cent_mean  \n",
      "count           49133.000000  \n",
      "mean               74.464519  \n",
      "std                54.742306  \n",
      "min                 1.000000  \n",
      "25%                33.000000  \n",
      "50%                70.386364  \n",
      "75%               104.777778  \n",
      "max               741.500000  \n",
      "\n",
      "ìƒ˜í”Œ (ìƒìœ„ 5ê°œ):\n",
      "                         firmname  year  dgr_cent  firmage  perf_all  \\\n",
      "0    Citicorp Venture Capital Ltd  1984     220.0     16.0         0   \n",
      "1                     Vista Group  1983      67.0      3.0         0   \n",
      "2  Summacrest Fiduciary Trust Inc  1984       NaN      0.0         0   \n",
      "3            Quidnet Capital Corp  1981       6.0      6.0         0   \n",
      "4             Adler & Company Inc  1984     136.0     19.0         1   \n",
      "\n",
      "   initial_dgr_cent_mean  initial_year  \n",
      "0                    NaN           NaN  \n",
      "1              55.335821        1981.0  \n",
      "2              16.000000        1984.0  \n",
      "3                    NaN           NaN  \n",
      "4                    NaN           NaN  \n",
      "\n",
      "ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤€ë¹„ ì™„ë£Œ!\n",
      "   - ë³€ìˆ˜ëª…: final_df\n",
      "   - ìš©ë„: íšŒê·€ ë¶„ì„, íŒ¨ë„ ë°ì´í„° ë¶„ì„\n",
      "   - ì¶”ì²œ ì €ì¥ í˜•ì‹: Parquet (ë¹ ë¥¸ I/O)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Step 7: ìµœì¢… ë°ì´í„°ì…‹ ì •ë³´\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… ìµœì¢… ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ë°ì´í„°ì…‹: final_df\")\n",
    "print(f\"   - Shape: {final_df.shape}\")\n",
    "print(f\"   - Level: Firm-Year\")\n",
    "print(f\"   - Key: (firmname, year)\")\n",
    "print(f\"   - ê¸°ê°„: {final_df['year'].min():.0f} ~ {final_df['year'].max():.0f}\")\n",
    "print(f\"   - Firm ìˆ˜: {final_df['firmname'].nunique():,}\")\n",
    "print(f\"   - ì´ ë³€ìˆ˜: {len(final_df.columns)}ê°œ (Market Heat, New Venture Funding Demand í¬í•¨)\")\n",
    "\n",
    "# ë³€ìˆ˜ ê·¸ë£¹ë³„ ì •ë¦¬\n",
    "print(f\"\\nğŸ“‹ ë³€ìˆ˜ ê·¸ë£¹:\")\n",
    "\n",
    "# 1. Key ë³€ìˆ˜\n",
    "key_vars = ['firmname', 'year']\n",
    "print(f\"\\n   1. Key ë³€ìˆ˜ ({len(key_vars)}ê°œ):\")\n",
    "for var in key_vars:\n",
    "    print(f\"      - {var}\")\n",
    "\n",
    "# 2. Network centrality\n",
    "network_vars = [col for col in final_df.columns \n",
    "                if col in ['dgr_cent', 'btw_cent', 'pwr_max', 'pwr_p0', 'pwr_p75', \n",
    "                          'pwr_p99', 'constraint', 'ego_dens']]\n",
    "print(f\"\\n   2. Network Centrality ({len(network_vars)}ê°œ):\")\n",
    "for var in network_vars:\n",
    "    print(f\"      - {var}\")\n",
    "\n",
    "# 3. Firm basics\n",
    "firm_basic_vars = [col for col in final_df.columns \n",
    "                   if col in ['firmage', 'industry_blau', 'perf_IPO', 'perf_MnA', \n",
    "                             'perf_all', 'early_stage_ratio', 'firm_hq_CAMA', \n",
    "                             'inv_amt', 'inv_num']]\n",
    "print(f\"\\n   3. Firm Basics ({len(firm_basic_vars)}ê°œ):\")\n",
    "for var in firm_basic_vars:\n",
    "    print(f\"      - {var}\")\n",
    "\n",
    "# 4. Initial partner status\n",
    "initial_status_vars = [col for col in final_df.columns if col.startswith('initial_') \n",
    "                       and col.endswith(('_mean', '_max', '_min'))]\n",
    "print(f\"\\n   4. Initial Partner Status ({len(initial_status_vars)}ê°œ):\")\n",
    "print(f\"      - {len(initial_status_vars)//3}ê°œ ì¤‘ì‹¬ì„± Ã— 3ê°œ ì§‘ê³„ (mean/max/min)\")\n",
    "print(f\"      - ì˜ˆ: {initial_status_vars[:3]}\")\n",
    "\n",
    "# 5. VC Reputation\n",
    "rep_vars = [col for col in final_df.columns \n",
    "            if col.startswith('rep_') or col == 'VC_reputation' or col == 'fundingAge']\n",
    "print(f\"\\n   5. VC Reputation ({len(rep_vars)}ê°œ):\")\n",
    "if rep_vars:\n",
    "    for var in rep_vars:\n",
    "        print(f\"      - {var}\")\n",
    "else:\n",
    "    print(f\"      - (ë³€ìˆ˜ ì—†ìŒ)\")\n",
    "\n",
    "# 6. Geographic Distance (Firm-Year Level)\n",
    "geo_company_vars = [col for col in final_df.columns if col.startswith('geo_dist_company')]\n",
    "geo_copartner_vars = [col for col in final_df.columns if col.startswith('geo_dist_copartner')]\n",
    "print(f\"\\n   6. Geographic Distance - VC-Company ({len(geo_company_vars)}ê°œ):\")\n",
    "if geo_company_vars:\n",
    "    for var in geo_company_vars:\n",
    "        print(f\"      - {var}\")\n",
    "else:\n",
    "    print(f\"      - (ë³€ìˆ˜ ì—†ìŒ)\")\n",
    "\n",
    "print(f\"\\n   7. Geographic Distance - VC-Co-Partner ({len(geo_copartner_vars)}ê°œ):\")\n",
    "if geo_copartner_vars:\n",
    "    for var in geo_copartner_vars:\n",
    "        print(f\"      - {var}\")\n",
    "else:\n",
    "    print(f\"      - (ë³€ìˆ˜ ì—†ìŒ)\")\n",
    "\n",
    "# 7. Market Heat (Industry-Level)\n",
    "market_heat_vars = [col for col in final_df.columns if col == 'market_heat']\n",
    "print(f\"\\n   8. Market Heat ({len(market_heat_vars)}ê°œ):\")\n",
    "if market_heat_vars:\n",
    "    for var in market_heat_vars:\n",
    "        print(f\"      - {var}\")\n",
    "else:\n",
    "    print(f\"      - (ë³€ìˆ˜ ì—†ìŒ)\")\n",
    "\n",
    "# 8. New Venture Funding Demand (Industry-Level, Current Year)\n",
    "demand_vars = [col for col in final_df.columns if col == 'new_venture_demand']\n",
    "print(f\"\\n   9. New Venture Funding Demand ({len(demand_vars)}ê°œ):\")\n",
    "if demand_vars:\n",
    "    for var in demand_vars:\n",
    "        print(f\"      - {var} (current year, ln(count of first-round US ventures in year t))\")\n",
    "        print(f\"        â†’ Panel ë¶„ì„ ì‹œ lagging í•„ìš” (ì˜ˆ: year t-1 ì‚¬ìš©)\")\n",
    "else:\n",
    "    print(f\"      - (ë³€ìˆ˜ ì—†ìŒ)\")\n",
    "\n",
    "# 9. Meta info\n",
    "meta_vars = [col for col in final_df.columns \n",
    "             if col in ['initial_year', 'n_initial_partners', 'n_partner_years']]\n",
    "print(f\"\\n   10. Meta Info ({len(meta_vars)}ê°œ):\")\n",
    "for var in meta_vars:\n",
    "    print(f\"      - {var}\")\n",
    "\n",
    "# ê¸°ìˆ  í†µê³„ ìƒ˜í”Œ\n",
    "print(f\"\\nğŸ“ˆ ê¸°ìˆ  í†µê³„ (ì£¼ìš” ë³€ìˆ˜):\")\n",
    "sample_vars = ['dgr_cent', 'firmage', 'industry_blau', 'perf_all', \n",
    "               'inv_num', 'initial_dgr_cent_mean']\n",
    "print(final_df[sample_vars].describe())\n",
    "\n",
    "print(f\"\\nìƒ˜í”Œ (ìƒìœ„ 5ê°œ):\")\n",
    "display_cols = ['firmname', 'year', 'dgr_cent', 'firmage', 'perf_all', \n",
    "                'initial_dgr_cent_mean', 'initial_year']\n",
    "print(final_df[display_cols].head())\n",
    "\n",
    "print(f\"\\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "print(f\"   - ë³€ìˆ˜ëª…: final_df\")\n",
    "print(f\"   - ìš©ë„: íšŒê·€ ë¶„ì„, íŒ¨ë„ ë°ì´í„° ë¶„ì„\")\n",
    "print(f\"   - ì¶”ì²œ ì €ì¥ í˜•ì‹: Parquet (ë¹ ë¥¸ I/O)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80d2bfd",
   "metadata": {},
   "source": [
    "#### Final Sampling & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96c830b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¶„ì„ ê°€ëŠ¥ ìƒ˜í”Œ í•„í„°ë§ ì™„ë£Œ\n",
      "  - ì „ì²´: 67,027  â†’  ë¶„ì„ ê°€ëŠ¥: 67,026  (ì”ì¡´ 100.0%)\n",
      "  - Drop counts (ì¡°ê±´ë³„ ì¤‘ë³µ ì§‘ê³„): {'year_range': 0, 'firm_basics': 1, 'centrality': 0, 'initial_status': 0, 'performance': 0}\n"
     ]
    }
   ],
   "source": [
    "# === ë¶„ì„ ê°€ëŠ¥ ìƒ˜í”Œ í•„í„°ë§ (ìµœì¢… ë¶„ì„ìš©) ===\n",
    "# ì„¤ì •: í•„ìš”í•œ ì¡°ê±´ë§Œ Trueë¡œ ì¼œì„œ ì‚¬ìš©\n",
    "ANALYSIS_REQUIREMENTS = {\n",
    "    'require_year_range': True,   # ë¶„ì„ ê¸°ê°„(START_YEAR~END_YEAR)ì— ì†í•˜ëŠ” firm-yearë§Œ ìœ ì§€\n",
    "    'require_firm_basics': True,  # ê¸°ë³¸ íŠ¹ì„±(firmage, firm_hq)ì´ ëª¨ë‘ ê´€ì¸¡ëœ ê´€ì¸¡ì¹˜ë§Œ í—ˆìš©\n",
    "    'require_centrality': False,   # ë„¤íŠ¸ì›Œí¬ì— ë“±ì¥í•œ ê´€ì¸¡ë§Œ ì‚¬ìš©(in_network=1 ë˜ëŠ” ì¤‘ì•™ì„± ì»¬ëŸ¼ ì¤‘ 1ê°œ ì´ìƒ notna)\n",
    "    'require_initial_status': False,  # ì´ˆê¸° ì—°ë„(initial_year)ê°€ ìˆëŠ” firmë§Œ ì‚¬ìš©(initial_* ë³€ìˆ˜ ë¶„ì„ ì‹œ True)\n",
    "    'require_performance': False      # ì„±ê³¼ ì§€í‘œ(perf_IPO, perf_MnA, perf_all)ê°€ ëª¨ë‘ ê´€ì¸¡ëœ ê´€ì¸¡ì¹˜ë§Œ í—ˆìš©\n",
    "}\n",
    "\n",
    "df0 = final_df\n",
    "\n",
    "# 1) ì¡°ê±´ë³„ ë§ˆìŠ¤í¬ êµ¬ì„±\n",
    "year_ok = df0['year'].between(START_YEAR, END_YEAR) if ANALYSIS_REQUIREMENTS['require_year_range'] else pd.Series(True, index=df0.index)\n",
    "\n",
    "basics_cols = [c for c in ['firmage','firm_hq'] if c in df0.columns]\n",
    "basics_ok = df0[basics_cols].notna().all(axis=1) if (ANALYSIS_REQUIREMENTS['require_firm_basics'] and basics_cols) else pd.Series(True, index=df0.index)\n",
    "\n",
    "cent_cols = [c for c in ['dgr_cent','btw_cent','pwr_max','pwr_p0','pwr_p75','pwr_p99','constraint','ego_dens'] if c in df0.columns]\n",
    "if ANALYSIS_REQUIREMENTS['require_centrality']:\n",
    "    if 'in_network' in df0.columns:\n",
    "        centrality_ok = df0['in_network'].eq(1)\n",
    "    else:\n",
    "        centrality_ok = df0[cent_cols].notna().any(axis=1) if cent_cols else pd.Series(False, index=df0.index)\n",
    "else:\n",
    "    centrality_ok = pd.Series(True, index=df0.index)\n",
    "\n",
    "initial_ok = df0['initial_year'].notna() if ANALYSIS_REQUIREMENTS['require_initial_status'] else pd.Series(True, index=df0.index)\n",
    "\n",
    "perf_cols = [c for c in ['perf_IPO','perf_MnA','perf_all'] if c in df0.columns]\n",
    "performance_ok = df0[perf_cols].notna().all(axis=1) if (ANALYSIS_REQUIREMENTS['require_performance'] and perf_cols) else pd.Series(True, index=df0.index)\n",
    "\n",
    "# 2) ì¢…í•© ë§ˆìŠ¤í¬ ë° í•„í„°ë§\n",
    "eligible_mask = year_ok & basics_ok & centrality_ok & initial_ok & performance_ok\n",
    "analysis_df = df0.loc[eligible_mask].copy()\n",
    "\n",
    "# 3) ìš”ì•½\n",
    "print(\"âœ… ë¶„ì„ ê°€ëŠ¥ ìƒ˜í”Œ í•„í„°ë§ ì™„ë£Œ\")\n",
    "print(f\"  - ì „ì²´: {len(df0):,}  â†’  ë¶„ì„ ê°€ëŠ¥: {len(analysis_df):,}  (ì”ì¡´ {len(analysis_df)/len(df0)*100:.1f}%)\")\n",
    "drop_reasons = {\n",
    "    'year_range': (~year_ok).sum(),\n",
    "    'firm_basics': (~basics_ok).sum(),\n",
    "    'centrality': (~centrality_ok).sum(),\n",
    "    'initial_status': (~initial_ok).sum(),\n",
    "    'performance': (~performance_ok).sum()\n",
    "}\n",
    "print(\"  - Drop counts (ì¡°ê±´ë³„ ì¤‘ë³µ ì§‘ê³„):\", {k: int(v) for k, v in drop_reasons.items()})\n",
    "\n",
    "# í•„ìš” ì‹œ ìµœì¢… ë°ì´í„° êµì²´\n",
    "# final_df = analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0090641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ\n",
      "  - Parquet: analysis_outputs/final_analysis_1980_2022_251110_2338.parquet\n",
      "  - Feather: analysis_outputs/final_analysis_1980_2022_251110_2338.feather\n",
      "  - CSV(sample): analysis_outputs/final_analysis_sample_1980_2022_n1000_251110_2338.csv (1,000 rows)\n"
     ]
    }
   ],
   "source": [
    "# === ìµœì¢… ë¶„ì„ ë°ì´í„° ì €ì¥ (Rì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥) ===\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# 0) ì„¤ì •\n",
    "CSV_SAMPLE_N = 1000          # CSVë¡œ ì €ì¥í•  ìƒ˜í”Œ ìˆ˜ (None ë˜ëŠ” 0ì´ë©´ CSV ì €ì¥ ìƒëµ)\n",
    "CSV_SAMPLE_RANDOM = True     # True: ë¬´ì‘ìœ„ ìƒ˜í”Œ, False: ìƒìœ„ Nê°œ\n",
    "CSV_SAMPLE_SEED = 42         # ë¬´ì‘ìœ„ ìƒ˜í”Œ ì‹œë“œ\n",
    "\n",
    "OUTPUT_DIR = Path(\"./analysis_outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ë‚ ì§œì‹œê°„ ìŠ¤íƒ¬í”„ (ì˜ˆ: 251028_2359)\n",
    "STAMP = datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "\n",
    "# 1) ì¸ë±ìŠ¤ ë¦¬ì…‹\n",
    "analysis_df = analysis_df.reset_index(drop=True)\n",
    "\n",
    "# 2) íŒŒì¼ ê²½ë¡œ (ìŠ¤íƒ¬í”„ ì¶”ê°€)\n",
    "parquet_path = OUTPUT_DIR / f\"final_analysis_{START_YEAR}_{END_YEAR}_{STAMP}.parquet\"\n",
    "feather_path = OUTPUT_DIR / f\"final_analysis_{START_YEAR}_{END_YEAR}_{STAMP}.feather\"\n",
    "csv_path = OUTPUT_DIR / f\"final_analysis_sample_{START_YEAR}_{END_YEAR}_n{CSV_SAMPLE_N}_{STAMP}.csv\"\n",
    "\n",
    "# 3) Parquet ì €ì¥ (R: arrow::read_parquet)\n",
    "analysis_df.to_parquet(parquet_path, index=False)\n",
    "\n",
    "# 4) Feather ì €ì¥ (R: arrow::read_feather)\n",
    "try:\n",
    "    analysis_df.to_feather(feather_path)\n",
    "except Exception as e:\n",
    "    print(f\"Feather ì €ì¥ ìƒëµ(ì—ëŸ¬): {e}\")\n",
    "\n",
    "# 5) CSV ìƒ˜í”Œ ì €ì¥ (ìš©ëŸ‰ ì œí•œìš©)\n",
    "if CSV_SAMPLE_N and CSV_SAMPLE_N > 0:\n",
    "    if CSV_SAMPLE_N >= len(analysis_df):\n",
    "        csv_sample = analysis_df\n",
    "    else:\n",
    "        csv_sample = (\n",
    "            analysis_df.sample(n=CSV_SAMPLE_N, random_state=CSV_SAMPLE_SEED)\n",
    "            if CSV_SAMPLE_RANDOM else\n",
    "            analysis_df.head(CSV_SAMPLE_N)\n",
    "        )\n",
    "    csv_sample.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"âœ… ì €ì¥ ì™„ë£Œ\")\n",
    "print(f\"  - Parquet: {parquet_path}\")\n",
    "print(f\"  - Feather: {feather_path}\")\n",
    "if CSV_SAMPLE_N and CSV_SAMPLE_N > 0:\n",
    "    print(f\"  - CSV(sample): {csv_path} ({len(csv_sample):,} rows)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ba8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affff230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef0da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db9d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5740845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec341b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b3a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070510c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae8dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n================================================================================\\nì§„ë‹¨: Initial Ties ë§¤ì¹­ ë¬¸ì œ í™•ì¸ (í•´ê²°ë¨)\\n================================================================================\\n\\nì§„ë‹¨ ê²°ê³¼:\\n----------\\n1. ë°ì´í„° í¬ê¸°:\\n   - firm_vars_df_filtered: 10,431 rows, 3,140 firms (1990~2000ë…„ íˆ¬ì ì§‘í–‰)\\n   - initial_ties_df: 1,720 rows, 1,720 firms (1990~2000ë…„ initial ties í˜•ì„±)\\n\\n2. ê³µí†µ Firm:\\n   - ê³µí†µ firm: 1,720ê°œ âœ…\\n   - firm_vars only: 1,420ê°œ (initial ties ì—†ìŒ)\\n   - initial_ties only: 0ê°œ (ëª¨ë‘ ë§¤ì¹­ë¨)\\n\\n3. Missing 58.2%ì˜ ì˜ë¯¸:\\n   - 3,140ê°œ firm ì¤‘ 1,720ê°œë§Œ 1990~2000ë…„ì— initial tiesë¥¼ í˜•ì„±\\n   - ë‚˜ë¨¸ì§€ 1,420ê°œ firmì€:\\n     * 1990ë…„ ì´ì „ì— ì´ë¯¸ initial tiesë¥¼ í˜•ì„±í–ˆê±°ë‚˜ (established firms)\\n     * ë°ì´í„°ì— initial ties ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°\\n\\n4. ê²°ë¡ :\\n   - MergeëŠ” ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤! âœ…\\n   - Missingì€ ì˜ë„ëœ ê²°ê³¼ì…ë‹ˆë‹¤ (1990ë…„ ì´ì „ established firms)\\n   - R ì½”ë“œë„ ë™ì¼í•œ ë¡œì§ì…ë‹ˆë‹¤\\n\\n5. ë¶„ì„ ì‹œ í•´ì„:\\n   - initial_yearê°€ ìˆëŠ” 1,720 firms: 1990~2000 ì½”í˜¸íŠ¸ (treatment group)\\n   - initial_yearê°€ NaNì¸ 1,420 firms: í†µì œ ê·¸ë£¹ (established firms)\\n\\n================================================================================\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "ì§„ë‹¨: Initial Ties ë§¤ì¹­ ë¬¸ì œ í™•ì¸ (í•´ê²°ë¨)\n",
    "================================================================================\n",
    "\n",
    "ì§„ë‹¨ ê²°ê³¼:\n",
    "----------\n",
    "1. ë°ì´í„° í¬ê¸°:\n",
    "   - firm_vars_df_filtered: 10,431 rows, 3,140 firms (1990~2000ë…„ íˆ¬ì ì§‘í–‰)\n",
    "   - initial_ties_df: 1,720 rows, 1,720 firms (1990~2000ë…„ initial ties í˜•ì„±)\n",
    "\n",
    "2. ê³µí†µ Firm:\n",
    "   - ê³µí†µ firm: 1,720ê°œ âœ…\n",
    "   - firm_vars only: 1,420ê°œ (initial ties ì—†ìŒ)\n",
    "   - initial_ties only: 0ê°œ (ëª¨ë‘ ë§¤ì¹­ë¨)\n",
    "\n",
    "3. Missing 58.2%ì˜ ì˜ë¯¸:\n",
    "   - 3,140ê°œ firm ì¤‘ 1,720ê°œë§Œ 1990~2000ë…„ì— initial tiesë¥¼ í˜•ì„±\n",
    "   - ë‚˜ë¨¸ì§€ 1,420ê°œ firmì€:\n",
    "     * 1990ë…„ ì´ì „ì— ì´ë¯¸ initial tiesë¥¼ í˜•ì„±í–ˆê±°ë‚˜ (established firms)\n",
    "     * ë°ì´í„°ì— initial ties ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°\n",
    "   \n",
    "4. ê²°ë¡ :\n",
    "   - MergeëŠ” ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤! âœ…\n",
    "   - Missingì€ ì˜ë„ëœ ê²°ê³¼ì…ë‹ˆë‹¤ (1990ë…„ ì´ì „ established firms)\n",
    "   - R ì½”ë“œë„ ë™ì¼í•œ ë¡œì§ì…ë‹ˆë‹¤\n",
    "   \n",
    "5. ë¶„ì„ ì‹œ í•´ì„:\n",
    "   - initial_yearê°€ ìˆëŠ” 1,720 firms: 1990~2000 ì½”í˜¸íŠ¸ (treatment group)\n",
    "   - initial_yearê°€ NaNì¸ 1,420 firms: í†µì œ ê·¸ë£¹ (established firms)\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# # ì§„ë‹¨ ì½”ë“œ (í•„ìš” ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ì‹¤í–‰)\n",
    "# print(\"=\" * 80)\n",
    "# print(\"ì§„ë‹¨: Initial Ties ë§¤ì¹­ ë¬¸ì œ\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# # 1. ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´\n",
    "# print(f\"\\n1. ë°ì´í„°ì…‹ í¬ê¸°:\")\n",
    "# print(f\"   - firm_vars_df_filtered: {len(firm_vars_df_filtered)} rows, {firm_vars_df_filtered['firmname'].nunique()} firms\")\n",
    "# print(f\"   - initial_ties_df: {len(initial_ties_df)} rows, {initial_ties_df['firmname'].nunique()} firms\")\n",
    "\n",
    "# # 2. Firmname ìƒ˜í”Œ ë¹„êµ\n",
    "# print(f\"\\n2. Firmname ìƒ˜í”Œ ë¹„êµ:\")\n",
    "# print(f\"\\n   firm_vars_df_filtered (ìƒìœ„ 5ê°œ):\")\n",
    "# print(firm_vars_df_filtered['firmname'].head().tolist())\n",
    "# print(f\"\\n   initial_ties_df (ìƒìœ„ 5ê°œ):\")\n",
    "# print(initial_ties_df['firmname'].head().tolist())\n",
    "\n",
    "# # 3. ê³µí†µ firm í™•ì¸\n",
    "# common_firms = set(firm_vars_df_filtered['firmname']) & set(initial_ties_df['firmname'])\n",
    "# print(f\"\\n3. ê³µí†µ Firm:\")\n",
    "# print(f\"   - ê³µí†µ firm ìˆ˜: {len(common_firms)}\")\n",
    "# print(f\"   - firm_vars only: {firm_vars_df_filtered['firmname'].nunique() - len(common_firms)}\")\n",
    "# print(f\"   - initial_ties only: {initial_ties_df['firmname'].nunique() - len(common_firms)}\")\n",
    "\n",
    "# # 4. ìƒ˜í”Œ firm ì¶”ì \n",
    "# if len(common_firms) > 0:\n",
    "#     sample_firm = list(common_firms)[0]\n",
    "#     print(f\"\\n4. ìƒ˜í”Œ Firm ì¶”ì : {sample_firm}\")\n",
    "#     print(f\"\\n   firm_vars_df_filtered:\")\n",
    "#     print(firm_vars_df_filtered[firm_vars_df_filtered['firmname'] == sample_firm][['firmname', 'year']].head())\n",
    "#     print(f\"\\n   initial_ties_df:\")\n",
    "#     print(initial_ties_df[initial_ties_df['firmname'] == sample_firm][['firmname', 'initial_year']].head())\n",
    "# else:\n",
    "#     print(f\"\\n4. âš ï¸  ê³µí†µ firmì´ ì—†ìŠµë‹ˆë‹¤! Firmname ë¶ˆì¼ì¹˜ ë¬¸ì œ!\")\n",
    "    \n",
    "# # 5. Merge í…ŒìŠ¤íŠ¸\n",
    "# print(f\"\\n5. Merge í…ŒìŠ¤íŠ¸:\")\n",
    "# test_merge = firm_vars_df_filtered[['firmname', 'year']].head(10).merge(\n",
    "#     initial_ties_df[['firmname', 'initial_year']],\n",
    "#     on='firmname',\n",
    "#     how='left'\n",
    "# )\n",
    "# print(test_merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "103f91f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ë©”ëª¨ë¦¬ ì •ë¦¬: ì¤‘ê°„ ë³€ìˆ˜ ì œê±°\n",
    "# import gc\n",
    "\n",
    "# # ì œê±°í•  ë³€ìˆ˜ (ë„¤íŠ¸ì›Œí¬ ê°ì²´ + ì¤‘ê°„ ë°ì´í„°)\n",
    "# variables_to_delete = [\n",
    "#     'networks', 'imprinting_networks',  # ë„¤íŠ¸ì›Œí¬ (ê°€ì¥ í° ë©”ëª¨ë¦¬)\n",
    "#     'imprinting_centrality_df', 'centrality_df_filtered',  # ì¤‘ê°„ ì¤‘ì‹¬ì„±\n",
    "#     'filtered_round', 'initial_partners_df', 'initial_ties_with_cent',  # ì¤‘ê°„ ì²˜ë¦¬\n",
    "#     'full_initial_year_df', 'initial_year_df',  # ì¤‘ê°„ ì—°ë„\n",
    "#     'firm_vars_df', 'initial_ties_df_unique'  # í•„í„°ë§ ì „\n",
    "# ]\n",
    "\n",
    "# # ì œê±° ì‹¤í–‰\n",
    "# for var_name in variables_to_delete:\n",
    "#     if var_name in globals():\n",
    "#         del globals()[var_name]\n",
    "\n",
    "# gc.collect()\n",
    "\n",
    "# print(\"âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "# print(f\"   ì œê±°: {len(variables_to_delete)}ê°œ ë³€ìˆ˜\")\n",
    "# print(f\"\\nìœ ì§€ ë°ì´í„°:\")\n",
    "# print(f\"   - data: ì›ë³¸ ë°ì´í„°\")\n",
    "# print(f\"   - centrality_df: ì „ì²´ ì¤‘ì‹¬ì„±\")\n",
    "# print(f\"   - firm_vars_df_filtered: Firm ë³€ìˆ˜\")\n",
    "# print(f\"   - initial_ties_df: Initial Partner Status\")\n",
    "# print(f\"   - final_df: ìµœì¢… ë¶„ì„ ë°ì´í„° â­\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c381356",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Centrality NA handling per config\n",
    "# from vc_analysis.config import parameters as params_mod\n",
    "\n",
    "# # Load parameters\n",
    "# params = params_mod.DEFAULT_PARAMS\n",
    "# cent_params = params.centrality\n",
    "\n",
    "# # Create in_network dummy: 1 if any centrality is present, else 0\n",
    "# centrality_cols = ['dgr_cent', 'btw_cent', 'pwr_max', 'pwr_p0', 'pwr_p75', 'pwr_p99', 'constraint', 'ego_dens']\n",
    "# existing_cent_cols = [c for c in centrality_cols if c in final_df.columns]\n",
    "\n",
    "# if cent_params.create_in_network_dummy and existing_cent_cols:\n",
    "#     final_df['in_network'] = (~final_df[existing_cent_cols].isna()).any(axis=1).astype(int)\n",
    "\n",
    "# # Optionally zero-fill selected measures when missing\n",
    "# if cent_params.fill_missing_centrality_as_zero and cent_params.zero_fill_columns:\n",
    "#     for col in cent_params.zero_fill_columns:\n",
    "#         if col in final_df.columns:\n",
    "#             final_df[col] = final_df[col].fillna(0)\n",
    "\n",
    "# print(\"âœ… Centrality NA handling applied\")\n",
    "# if 'in_network' in final_df.columns:\n",
    "#     print(\"   - in_network dummy added:\", final_df['in_network'].value_counts().to_dict())\n",
    "# if cent_params.fill_missing_centrality_as_zero and cent_params.zero_fill_columns:\n",
    "#     print(\"   - Zero-filled columns:\", [c for c in cent_params.zero_fill_columns if c in final_df.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8198b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Initial status NaN ì›ì¸ í”Œë˜ê·¸ (ì••ì¶•/ì•ˆì „ ë²„ì „) ===\n",
    "\n",
    "\n",
    "\n",
    "# # 1) initial_* ì§‘ê³„ ì»¬ëŸ¼\n",
    "\n",
    "# # initial_status_cols will be calculated from tmp after merge (see below)\n",
    "\n",
    "\n",
    "\n",
    "# # 2) full history ê¸°ë°˜ ìµœì´ˆì—°ë„ ë§µ ìƒì„±\n",
    "\n",
    "# firm_initial_full = (\n",
    "\n",
    "#     full_initial_year_df[['firmname', 'initial_year']].drop_duplicates('firmname')\n",
    "\n",
    "#     if 'full_initial_year_df' in globals() and not full_initial_year_df.empty\n",
    "\n",
    "#     else data['round'][['firmname', 'year']].dropna().groupby('firmname', as_index=False)['year'].min().rename(columns={'year':'initial_year'})\n",
    "\n",
    "# )\n",
    "\n",
    "# firm_initial_full = firm_initial_full.rename(columns={'initial_year':'initial_year_full'})\n",
    "\n",
    "\n",
    "\n",
    "# # 3) final_dfì— ë³‘í•©(ì„ì‹œ í”„ë ˆì„)\n",
    "\n",
    "# tmp = final_df.merge(firm_initial_full, on='firmname', how='left')\n",
    "\n",
    "\n",
    "\n",
    "# # 4) ë³´ì¡° ì‹œë¦¬ì¦ˆ/ë§ˆìŠ¤í¬ (ì•ˆì „ ì ‘ê·¼)\n",
    "\n",
    "\n",
    "# # Recalculate initial_status_cols from tmp to ensure we check the correct columns\n",
    "# initial_status_cols = [c for c in tmp.columns if c.startswith('initial_') and c.endswith(('_mean', '_max', '_min'))]\n",
    "# iyf = tmp['initial_year_full'] if 'initial_year_full' in tmp.columns else pd.Series(np.nan, index=tmp.index)\n",
    "\n",
    "# iy  = tmp['initial_year']      if 'initial_year'      in tmp.columns else pd.Series(np.nan, index=tmp.index)\n",
    "\n",
    "\n",
    "\n",
    "# initial_year_present = iy.notna()\n",
    "\n",
    "# partners_zero_or_na = (\n",
    "\n",
    "#     (tmp['n_initial_partners'].isna() if 'n_initial_partners' in tmp.columns else True) |\n",
    "\n",
    "#     (tmp.get('n_initial_partners', 0) == 0) |\n",
    "\n",
    "#     (tmp['n_partner_years'].isna() if 'n_partner_years' in tmp.columns else True) |\n",
    "\n",
    "#     (tmp.get('n_partner_years', 0) == 0)\n",
    "\n",
    "# )\n",
    "\n",
    "# initial_status_all_nan = (tmp[initial_status_cols].isna().all(axis=1)) if initial_status_cols else pd.Series(False, index=tmp.index)\n",
    "\n",
    "\n",
    "\n",
    "# # 5) ë¶„ë¥˜ í”Œë˜ê·¸\n",
    "\n",
    "# outside_cohort = iyf.notna() & ~iyf.between(START_YEAR, END_YEAR) & iy.isna()\n",
    "\n",
    "# no_partners_at_foundation = initial_year_present & partners_zero_or_na\n",
    "\n",
    "# has_partners_but_no_centrality = initial_year_present & ~partners_zero_or_na & initial_status_all_nan\n",
    "\n",
    "# missing_other = initial_status_all_nan & ~outside_cohort & ~no_partners_at_foundation & ~has_partners_but_no_centrality\n",
    "\n",
    "\n",
    "\n",
    "# # 6) í”Œë˜ê·¸ ì ìš©\n",
    "\n",
    "# tmp['initial_status_missing'] = initial_status_all_nan.astype(int)\n",
    "\n",
    "# tmp['initial_missing_outside_cohort'] = outside_cohort.astype(int)\n",
    "\n",
    "# tmp['initial_missing_no_partners'] = no_partners_at_foundation.astype(int)\n",
    "\n",
    "# tmp['initial_missing_no_centrality'] = has_partners_but_no_centrality.astype(int)\n",
    "\n",
    "# tmp['initial_missing_other'] = missing_other.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# # 7) â€˜otherâ€™ â†’ â€˜no_partnersâ€™ ì¬ë¶„ë¥˜ (ì½”í˜¸íŠ¸ ë‚´ ìµœì´ˆì—°ë„ëŠ” ìˆìœ¼ë‚˜ t1~t3 íŒŒíŠ¸ë„ˆê°€ ì „í˜€ ì—†ë˜ firm)\n",
    "\n",
    "# firms_with_partners = set(initial_ties_df['firmname']) if 'initial_ties_df' in globals() else set()\n",
    "\n",
    "# no_partners_strict = (\n",
    "\n",
    "#     tmp['initial_status_missing'].eq(1) &\n",
    "\n",
    "#     iyf.between(START_YEAR, END_YEAR) &\n",
    "\n",
    "#     ~tmp['firmname'].isin(firms_with_partners)\n",
    "\n",
    "# )\n",
    "\n",
    "# tmp['initial_missing_no_partners'] = (tmp['initial_missing_no_partners'].astype(bool) | no_partners_strict).astype(int)\n",
    "\n",
    "# tmp['initial_missing_other'] = (\n",
    "\n",
    "#     tmp['initial_status_missing'].eq(1) &\n",
    "\n",
    "#     tmp['initial_missing_outside_cohort'].eq(0) &\n",
    "\n",
    "#     tmp['initial_missing_no_partners'].eq(0) &\n",
    "\n",
    "#     tmp['initial_missing_no_centrality'].eq(0)\n",
    "\n",
    "# ).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# # 8) ìµœì¢… ë°˜ì˜ + ìš”ì•½\n",
    "\n",
    "# final_df = tmp\n",
    "\n",
    "# print(\"ğŸ” Initial status NaN ì›ì¸ í”Œë˜ê·¸ ìš”ì•½:\")\n",
    "\n",
    "# for col in ['initial_status_missing','initial_missing_outside_cohort','initial_missing_no_partners','initial_missing_no_centrality','initial_missing_other']:\n",
    "\n",
    "#     cnt = int(final_df[col].sum())\n",
    "\n",
    "#     print(f\"  - {col}: {cnt:,} ({cnt/len(final_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "validation_initial_status",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Validation: initial_status_missing Consistency Check ===\n",
    "# # This cell validates that initial_status_missing=1 means ALL initial_*_mean/max/min are NaN\n",
    "\n",
    "# print(\"=\" * 80)\n",
    "# print(\"Validation: initial_status_missing Consistency\")\n",
    "# print(\"=\" * 80)\n",
    "\n",
    "# # Recalculate initial_status_cols to ensure we have the latest columns\n",
    "# initial_status_cols_current = [c for c in final_df.columns \n",
    "#                                  if c.startswith('initial_') and c.endswith(('_mean', '_max', '_min'))]\n",
    "\n",
    "# print(f\"\\nCurrent initial_status_cols: {len(initial_status_cols_current)} columns\")\n",
    "# if initial_status_cols_current:\n",
    "#     print(f\"  Sample: {initial_status_cols_current[:5]}\")\n",
    "\n",
    "# # Check rows where initial_status_missing = 1\n",
    "# missing_mask = final_df['initial_status_missing'] == 1\n",
    "# n_missing = missing_mask.sum()\n",
    "\n",
    "# print(f\"\\nRows with initial_status_missing=1: {n_missing:,}\")\n",
    "\n",
    "# if n_missing > 0 and initial_status_cols_current:\n",
    "#     # Check if any of these rows have non-null values in initial_status_cols\n",
    "#     missing_df = final_df.loc[missing_mask, ['firmname', 'year'] + initial_status_cols_current]\n",
    "    \n",
    "#     # Check for any non-null values\n",
    "#     has_values = missing_df[initial_status_cols_current].notna().any(axis=1)\n",
    "#     n_with_values = has_values.sum()\n",
    "    \n",
    "#     print(f\"\\nâš ï¸ Rows with initial_status_missing=1 BUT have initial_*_mean/max/min values: {n_with_values:,}\")\n",
    "    \n",
    "#     if n_with_values > 0:\n",
    "#         print(\"\\nâŒ ERROR DETECTED!\")\n",
    "#         print(\"   initial_status_missing=1 should mean ALL initial_*_mean/max/min are NaN\")\n",
    "#         print(\"\\nSample of problematic rows:\")\n",
    "#         problematic = missing_df.loc[has_values, ['firmname', 'year'] + initial_status_cols_current[:3]]\n",
    "#         print(problematic.head(10))\n",
    "        \n",
    "#         print(\"\\nğŸ” Checking which columns have values:\")\n",
    "#         for col in initial_status_cols_current:\n",
    "#             n_non_null = missing_df[col].notna().sum()\n",
    "#             if n_non_null > 0:\n",
    "#                 pct = n_non_null / n_missing * 100\n",
    "#                 print(f\"  - {col}: {n_non_null:,} non-null ({pct:.1f}% of missing rows)\")\n",
    "        \n",
    "#         print(\"\\nğŸ’¡ Possible causes:\")\n",
    "#         print(\"   1. initial_status_cols was calculated before all initial_* variables were merged\")\n",
    "#         print(\"   2. Some initial_* variables were added after initial_status_missing was calculated\")\n",
    "#         print(\"   3. Merge timing issue\")\n",
    "#     else:\n",
    "#         print(\"\\nâœ… No issues found: All rows with initial_status_missing=1 have NaN for initial_*_mean/max/min\")\n",
    "    \n",
    "#     # Also check other initial_* variables (for information)\n",
    "#     other_initial_cols = [c for c in final_df.columns \n",
    "#                           if c.startswith('initial_') and not c.endswith(('_mean', '_max', '_min'))\n",
    "#                           and c not in ['initial_year', 'initial_status_missing', \n",
    "#                                         'initial_missing_outside_cohort', 'initial_missing_no_partners',\n",
    "#                                         'initial_missing_no_centrality', 'initial_missing_other']]\n",
    "    \n",
    "#     if other_initial_cols:\n",
    "#         print(f\"\\nğŸ“Š Other initial_* variables (not _mean/_max/_min): {len(other_initial_cols)}\")\n",
    "#         print(f\"  Sample: {other_initial_cols[:5]}\")\n",
    "        \n",
    "#         # Check if these have values when initial_status_missing=1 (this is EXPECTED)\n",
    "#         other_has_values = final_df.loc[missing_mask, other_initial_cols].notna().any(axis=1)\n",
    "#         n_other_with_values = other_has_values.sum()\n",
    "        \n",
    "#         if n_other_with_values > 0:\n",
    "#             print(f\"\\n  â„¹ï¸  {n_other_with_values:,} rows have other initial_* values (EXPECTED)\")\n",
    "#             print(\"     These are NOT checked by initial_status_missing\")\n",
    "#             print(\"     (only initial_*_mean/max/min are checked)\")\n",
    "# else:\n",
    "#     print(\"\\nâœ… No rows with initial_status_missing=1 found, or no initial_status_cols\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
