# Suengjae Hong
# 2022-01-19
# VentureXpert Dta
# v2: n-1 network updates | one-year matrix in tie formation
## based on M1, 4.4 mins on data manipulation
## 2.1 mins on data save (fst format)

rm(list=ls())

start_time <- Sys.time()

#### PACKAGE ####

# Two packages are used: igraph & data.table for this R script
# for data preprocessing
if (!require('igraph')) install.packages('igraph'); library('igraph')
if (!require('data.table')) install.packages('data.table'); library('data.table')
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
if (!require('foreign')) install.packages('foreign'); library(foreign)

# for parallel running
if (!require('doParallel')) install.packages('doParallel'); library('doParallel')
if (!require('foreach')) install.packages('foreach'); library('foreach')
# if (!require('tcltk')) install.packages('tcltk'); library('tcltk')

# for saving compressed data
if (!require('fst')) install.packages('fst'); library('fst')

# for modeling
if (!require('Zelig')) install.packages('Zelig'); library('Zelig') # relogit if use
if (!require('Epi')) install.packages('Epi'); library('Epi') # relogit if use

# for visualization
#if (!require('sjPlot')) install.packages('sjPlot'); library('sjPlot')
#if (!require('sjmisc')) install.packages('sjmisc'); library('sjmisc')
#if (!require('sjlabelled')) install.packages('sjlabelled'); library('sjlabelled')

# setting wd
wd <- c("/Users/suengj/Library/Mobile Documents/com~apple~CloudDocs/suengj/Academia/Research/03_project/00_Yang, Rhee, Ma/data",
        "/Users/suengj/Library/Mobile Documents/com~apple~CloudDocs/suengj/Academia/Research/03_project/00_Yang, Rhee, Ma/results")

setwd(wd[1]) # Change the working directory

# Setting -----
select <- dplyr::select

# core setting
capacity <- 0.8
cores <- round(parallel::detectCores()*capacity,digits=0)
registerDoParallel(cores=cores)

#### Data load ----
# I. 1. round dataframe generated by read.csv() function {base}
round <- read.csv("roundall.csv", header = TRUE)         
round <- round[round$firmname != "Undisclosed Firm", ]   
round <- round[round$comname != "Undisclosed Company", ] 

# I. 2. by using foreign packages load company/firm data
comdta <- read.dta('companydata.dta') %>% as_tibble()
funddta <- read.dta('firmdata.dta') %>% as_tibble() %>% 
  select(starts_with('fund'),'firmname')

firmdta <- read.dta('firmdata.dta') %>% as_tibble() %>%
  select(-starts_with('fund')) %>%
  mutate(fnd_year = as.integer(str_sub(date_fnd,
                                       nchar(date_fnd)-3,nchar(date_fnd))))

# I.3. filtering round data
filtered_comdta <- comdta %>%
  select(comname, comindmjr)

filtered_round <- left_join(round, filtered_comdta,
                           by="comname")

filtered_round <- filtered_round %>%
  filter(comindmjr == "Biotechnology")

# I. 4. trim unnecessary variables to make the edgelist
round       <- filtered_round
round       <- round[ ,c("year","rnddate","firmname","comname")]
round$event <- factor(paste(round$comname, round$rnddate, sep ="-"))
round       <- round[ ,c("year", "firmname", "event")]

# merge fst file if need
# mergeddta <- read_fst('merged_v2.fst') %>% as_tibble()

# I. 4 corporate VC list
corporatevc <- data.table(read.csv("corporateVC.csv", header = TRUE)) %>% as_tibble()

# analysis setting
time_window <- 5
edge_cutpoint <- 5 # Just in case, but not applied in this study

#### Defining function ####

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# II. 1. Function 1: generate the igraph of VC to VC
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# matrix value should be t-1, (because, dv = t)
VC_matrix <- function(round, year, time_window = NULL, edge_cutpoint = NULL) {
  
  if(!is.null(time_window)) {
    edgelist <- round[round$year <= year-1 & round$year >= year-time_window, 
                      c("firmname", "event")]
  } else {
    edgelist <- round[round$year == year-1, c("firmname", "event")]
  }
  
  twomode <- graph_from_edgelist(as.matrix(edgelist), directed = FALSE)
  
  V(twomode)$type <- V(twomode)$name %in% edgelist[,2]
  
  onemode <- bipartite_projection(twomode)$proj1
  
  if(!is.null(edge_cutpoint)) {
  } else {}
  
  return(onemode)
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# II. 2. Function 2: generate the edgelist of realized VC-to-VC ties 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# realized tie = dv
VC_realized_ties <- function(round, year, time_window = NULL, edge_cutpoint = NULL) {
  
  if(!is.null(time_window)) {
    edgelist <- round[round$year <= year & round$year >= year-time_window + 1, 
                      c("firmname", "event")]
  } else {
    edgelist <- round[round$year == year, c("firmname", "event")]
  }
  
  twomode <- graph_from_edgelist(as.matrix(edgelist), directed = FALSE)
  
  V(twomode)$type <- V(twomode)$name %in% edgelist[,2]
  
  onemode <- bipartite_projection(twomode)$proj1
  
  if(!is.null(edge_cutpoint)) {
    onemode <- delete_edges(onemode, which(E(onemode)$weight < edge_cutpoint))
  } else {}
  
  return(as_edgelist(onemode, names = TRUE))
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# II. 3. Function : generate the edgelist of 
#                  all possible VC-to-VC ties (realized + unrealized)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

VC_all_possible_ties <- function(round, year, time_window = NULL) {
  
  if(!is.null(time_window)) {
    edgelist <- round[round$year <= year & round$year >= year-time_window + 1, 
                      c("firmname", "event")]
  } else {
    edgelist <- round[round$year == year, c("firmname", "event")]
  }
  
  twomode <- graph_from_edgelist(as.matrix(edgelist), directed = FALSE)
  
  V(twomode)$type <- V(twomode)$name %in% edgelist[,2]
  
  onemode <- bipartite_projection(twomode)$proj1
  
  return(t(combn(V(onemode)$name,2))) 
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# II. 4. Function 4: All_possible_ties - realized_ties 
# "data.table" packages enables much faster treatments
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

VC_unrealized_ties <- function(allties, realizedties) {
  
  DTall  <- setkey(data.table(allties))
  DTreal <- setkey(data.table(realizedties))
  
  DTmatch <- DTall %>%
    mutate(V3=ifelse(row_number() %in% DTall[DTreal,which=TRUE],1,0)) %>%
    as.matrix()
  
  colnames(DTmatch) <- NULL
  rownames(DTmatch) <- NULL
  
  return(DTmatch) # result is "matrix" object
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# II. 5. Function 5: Centrality calculations: degree, betweeness, 
#                    & 3 power cent with different beta 
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

VC_centralities <- function(round, year, time_window, edge_cutpoint) {
  
  adjmatrix <- VC_matrix(round, year, time_window, edge_cutpoint)
  
  # beta (= 1/max_egenvalues) range determination
  upsilon <- max(
    eigen(
      as_adjacency_matrix(adjmatrix)
    )$values
  )
  
  degree_centrality     <- degree(adjmatrix)
  betweenness_centralty <- betweenness(adjmatrix)
  power_centralty_pmax  <- power_centrality(adjmatrix, exponent = 1/upsilon)
  power_centralty_nmax  <- power_centrality(adjmatrix, exponent = -1/upsilon)
  power_centralty_zero  <- power_centrality(adjmatrix, exponent = 0)
  
  constraint_value <- constraint(adjmatrix) # added constraint
  
  result <- data.table(cbind(degree_centrality, 
                             betweenness_centralty,
                             power_centralty_pmax,
                             power_centralty_nmax,
                             power_centralty_zero,
                             
                             constraint_value)
                       , keep.rownames = TRUE)
  
  return(result)
}

# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# III. Sampling: select all of dv1==1 and randomly select dv1==0 with assigned n
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# samling group by year
dta_sampling <- function(dta,y,m){
  start_time <- Sys.time()
  
  dta <- dta %>%
    filter(year>=y)
  
  count_by_year <- dta %>% 
    filter(dv==1) %>%
    group_by(year) %>%
    summarise(n=n()) %>%
    select(year,n)
  
  set.seed(123)
  
  sampling <- dta %>%
    filter(dv==0) %>%
    select(year,p1_id,p2_id) %>%
    group_by(year) %>%
    nest() %>% ungroup() %>%
    left_join(.,count_by_year,
              by='year') %>%
    na.omit() %>%
    mutate(samp = map2(data,n*m,sample_n)) %>%
    select(year,samp) %>%
    unnest(samp)
  
  realized <- dta %>%
    filter(dv==1) %>%
    select(year,p1_id,p2_id)
  
  sample_id <- bind_rows(sampling,realized)
  
  sampleddta <- left_join(sample_id,dta,
                          by=c('p1_id'='p1_id',
                               'p2_id'='p2_id',
                               'year'='year'))
  end_time <- Sys.time()
  
  print(end_time - start_time)
  
  return(sampleddta)
}

# sampling simply w/o considering year as group
dta_sampling2 <- function(dta,y,m){
  dta <- dta %>%
    filter(year>=y)
  
  realized <- dta %>% 
    filter(dv==1) %>%
    select(year, p1_id, p2_id)
  
  set.seed(123)
  
  sampling <- dta %>%
    filter(dv==0) %>%
    select(year, p1_id, p2_id) %>%
    sample_n(.,
             NROW(realized)*m)
  
  sample_id <- bind_rows(sampling,realized)
  
  sampleddta <- left_join(sample_id,dta,
                          by=c('p1_id'='p1_id',
                               'p2_id'='p2_id',
                               'year'='year'))
  
  return(sampleddta)
  
} 

#### Data Arrangement ----
# vc id
vcnm <- unique(round$firmname) %>% as_tibble() %>%
  mutate(vid=paste0('v',row_number()))

# Centrality for t-1 centrality
cent <- foreach(y=1980:2011,
                .combine=rbind) %dopar% {
                  cbind(year=y,VC_centralities(round,y,5,5))
                }

cent <- cent %>% as_tibble()
colnames(cent)[2] <- "firmname"

# dyad full
dyads_full <- foreach(y=1980:2011,.combine=rbind) %dopar% {
  cbind(year=y,
        VC_unrealized_ties(
          VC_all_possible_ties(round,y,1), # only one year
          VC_realized_ties(round,y,1) # only one year
        ))
}

dyads_full <- dyads_full %>% as_tibble(.name_repair='unique') # due to compatibility, updates the option

base::names(dyads_full) <- c('year','vc1','vc2','realized')

dyads_full$year <- as.integer(dyads_full$year)
dyads_full$realized <- as.integer(dyads_full$realized)

# data merge
mergeddta <- left_join(dyads_full,cent,
                       by=c('year'='year',
                            'vc1'='firmname'))

mergeddta <- left_join(mergeddta,cent,
                       by=c('year'='year',
                            'vc2'='firmname'))

mergeddta <- left_join(mergeddta,corporatevc,
                       by=c('vc1'='firmname')) 

mergeddta <- left_join(mergeddta,corporatevc,
                       by=c('vc2'='firmname'))

mergeddta <- left_join(mergeddta,vcnm,
                       by=c('vc1'='value'))

mergeddta <- left_join(mergeddta,vcnm,
                       by=c('vc2'='value'))

rm(cent, dyads_full)

# rename
base::names(mergeddta) <- c('year','p1','p2','dv',
                            'p1_dgr','p1_btw','p1_bp_pmax','p1_bp_nmax','p1_bp_0','p1_cons',
                            'p2_dgr','p2_btw','p2_bp_pmax','p2_bp_nmax','p2_bp_0','p2_cons',
                            'corp_p1','corp_p2','p1_id','p2_id')

mergeddta <- mergeddta %>%
  select(-c('p1','p2')) %>%
  mutate_at(vars('corp_p1','corp_p2'),~replace(.,is.na(.),0))

# final time = 4.8 mins

end_time <- Sys.time()

print(end_time - start_time)

# saving file with fst type (much faster and saving memory)
# reference: https://waterdata.usgs.gov/blog/formats/
start_time <- Sys.time()

write_fst(mergeddta,
          path='merged_v2_biotech.fst',
          compress=100)

end_time <- Sys.time()

print(end_time - start_time)

mergeddta <- read_fst('merged_v2.fst')

# system.time(fwrite(mergeddata, "merged.csv", na="", col.names = TRUE))

#### ANALYSIS ----
# 1:10 sampling in each year group from 1980
m <- 10
y <- 1980
dta <- dta_sampling(mergeddta,y,m) #; rm(mergeddta)
dta <- dta %>% mutate_at(vars('corp_p1','corp_p2'),~replace_na(.,0))
dta <- dta %>% replace(is.na(.),0)

# dta <- dta_sampling2(mergeddta,y,m) #; rm(mergeddta)

# variable creation
dta <- dta %>% 
  rowwise() %>%
  mutate(bp_d1_0 = abs(p1_bp_0 - p2_bp_0),
         bp_d1_pmax = abs(p1_bp_pmax - p2_bp_pmax), 
         bp_d1_nmax = abs(p1_bp_nmax - p2_bp_nmax),
         bp_d2_0 = bp_d1_0/sum(c(p1_bp_0,p2_bp_0)), # status dif (shipilov & greve)
         bp_d2_pmax = bp_d1_pmax/sum(c(p1_bp_pmax, p2_bp_pmax)),
         bp_d2_nmax = bp_d1_nmax/sum(c(p1_bp_nmax, p2_bp_nmax)),
         both_prv = ifelse(sum(c(corp_p1,corp_p2))==0,1,0), # H2 control
         both_cvc = ifelse(sum(c(corp_p1,corp_p2))==2,1,0), # H3 control
         prvcvc = ifelse(sum(c(corp_p1,corp_p2))==1,1,0), # H4 control
         nt_size_sum = sum(c(p1_dgr,p2_dgr)))

dta <- dta %>%
  mutate(bp_d2_0 = ifelse(is.na(bp_d2_0),0,bp_d2_0))

tdta <- dta %>%
  filter(year >=1990 & year < 1995)

# model
model_test <- survival::clogit(dv ~ log(nt_size_sum+1) + bp_d2_0 + strata(year),
                               tdta, 
                               method="approximate"); summary(model_test)

# model
model_0 <- survival::clogit(dv ~ log(nt_size_sum+1) + strata(year),
                               dta, 
                               method="approximate"); summary(model_0)

model_1 <- survival::clogit(dv ~ log(nt_size_sum+1) + bp_d2_0 + strata(year),
                               dta, 
                               method="approximate"); summary(model_1)

model_2 <- survival::clogit(dv ~ log(nt_size_sum+1) + both_prv*bp_d2_0 + strata(year),
                               dta, 
                               method="approximate"); summary(model_2)

model_3 <- survival::clogit(dv ~ log(nt_size_sum+1) + both_cvc*bp_d2_0 + strata(year),
                               dta, 
                               method="approximate"); summary(model_3)

model_4 <- survival::clogit(dv ~ log(nt_size_sum+1) + prvcvc*bp_d2_0 + strata(year),
                               dta, 
                               method="approximate"); summary(model_4)


# full model
model_5 <- survival::clogit(dv ~ log(nt_size_sum+1) + 
                              bp_d2_0*(both_prv + prvcvc),
                            dta,
                            method='approximate'); summary(model_5)

summary <- list(summary(model_0),
                summary(model_1),
                summary(model_2),
                summary(model_3),
                summary(model_4),
                summary(model_5))

# vif score
car::vif(model_5)

# as data frame
df_summary <- list(summary.glm(model_1)$coefficients,
                   summary.glm(model_2)$coefficients,
                   summary.glm(model_3)$coefficients,
                   summary.glm(model_4)$coefficients,
                   summary.glm(model_5)$coefficients)

# save file
setwd(wd[2])
for(i in 1:NROW(df_summary)){
  write.csv(df_summary[[i]],
            paste0('model_',i,'.csv'))
  
}

setwd(wd[1])


# visualization for results
tab_model(model_1,
          ci_method='wald') # taking longer time than expected

# end of code



model <- zelig(dv~p1_dgr + bp_d2_0,
               model='relogit',
               data=dta,
               case.control='prior',
               tau=NULL,
               bias.correct=TRUE)




# model
model_0 <- glm(dv~factor(year) + log(nt_size_sum+1),
               data=dta,
               family='binomial'); summary(model_0)

model_1 <- glm(dv~factor(year) + log(nt_size_sum+1)
               + bp_d2_0,
               data=dta,
               family='binomial'); summary(model_1)

model_2 <- glm(dv~factor(year) + log(nt_size_sum+1) + both_prv*bp_d2_0,
               data=dta,
               family='binomial'); summary(model_2)

model_3 <- glm(dv~factor(year) + log(nt_size_sum+1) + both_cvc*bp_d2_0,
               data=dta,
               family='binomial'); summary(model_3)

model_4 <- glm(dv~factor(year) + log(nt_size_sum+1) + prvcvc*bp_d2_0,
               data=dta,
               family='binomial'); summary(model_4)
